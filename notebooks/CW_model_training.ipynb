{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CW_model_training.ipynb \n",
    "\n",
    "This is based on the original notebook by the main author of the paper (`RADIPOP_model_training.ipynb`).\n",
    "\n",
    "\n",
    "At this point it is mostly a development notebook. A cleaned up version can be found at: \n",
    "`radipop_utils/tools/training_and_hyperparams_search_entry_point.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.stats import spearmanr\n",
    "import skopt\n",
    "\n",
    "import radipop_utils \n",
    "import radipop_utils.visualization\n",
    "import radipop_utils.features\n",
    "from radipop_utils.features import SpearmanReducerCont\n",
    "import radipop_utils.utils\n",
    "\n",
    "import radipop_utils.data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# load user/ system specific env variables:\n",
    "from dotenv import dotenv_values, find_dotenv\n",
    "config = dotenv_values(find_dotenv())  # load environment variables as dictionary\n",
    "\n",
    "path = Path(os.path.abspath(radipop_utils.__file__))\n",
    "RADIPOP_PACKAGE_ROOT = path.parent.parent\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##------  You will likely need to change this \n",
    "DATA_ROOT_DIRECTORY = Path(config[\"DATA_ROOT_DIRECTORY\"])\n",
    "OUTDIR = DATA_ROOT_DIRECTORY / \"radiomics\" / \"Dataset125_LSS\" \n",
    "DATASET = \"Dataset125_LSS\"\n",
    "RADIOMICS_OPTION = \"radipop_111\"\n",
    "NUM_SEARCHES = 20\n",
    "SEARCH_SCORING_METRIC = \"r2\"  # \"neg_root_mean_squared_error\"  \"r2\"\n",
    "SAVE_RESULTS = False\n",
    "##-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the the data: \n",
    "- load radiomics and HVPG values \n",
    "- utilize our custom split (previously defined and stratified on sex, scanner, status)\n",
    "- normalized the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load features and combine with predicted values: \n",
    "\n",
    "df_Tr, df_iTs, df_eTs = radipop_utils.data.load_HVPG_values_and_radiomics(DATASET=DATASET, RADIOMICS_OPTION=RADIOMICS_OPTION, DATA_ROOT_DIRECTORY=DATA_ROOT_DIRECTORY)\n",
    "print(f\"{len(df_Tr)=}, {len(df_eTs)=}, {len(df_iTs)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(df_Tr)\n",
    "# display(df_iTs)\n",
    "# display(df_eTs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_indices_CV5_Tr = radipop_utils.data.extract_CV_indices(df_Tr)\n",
    "\n",
    "X_Tr, Y_Tr, X_iTs, Y_iTs, X_eTs, Y_eTs = radipop_utils.data.preprocess_data(df_Tr, df_iTs, df_eTs, normalize_X=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot dendrogram\n",
    "corr = spearmanr(X_Tr).correlation\n",
    "\n",
    "# Ensure the correlation matrix is symmetric\n",
    "corr = (corr + corr.T) / 2\n",
    "np.fill_diagonal(corr, 1)\n",
    "\n",
    "# plt.matshow(corr)\n",
    "# plt.show()\n",
    "\n",
    "# We convert the correlation matrix to a distance matrix before performing\n",
    "# hierarchical clustering using Ward's linkage.\n",
    "distance_matrix = 1 - np.abs(corr)\n",
    "dist_linkage = hierarchy.ward(squareform(distance_matrix))\n",
    "plt.figure()\n",
    "dendro = hierarchy.dendrogram(\n",
    "    dist_linkage, no_labels=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decide on a rought range for the cut parameters for dendrogram\n",
    "split_params = [0.5, 0.75, 1, 2.75,  5, 7.5, 10]\n",
    "for split_param in split_params:\n",
    "    selector = SpearmanReducerCont(split_param=split_param)\n",
    "    print(f\"Selected features at height {split_param}:\", len(selector.fit(X_Tr, Y_Tr).selected_features))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit on `Tr` data with CV and estimate best model + hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bounds for hyperparameters\n",
    "param_bounds_rf = {\n",
    "    'feature_selection__split_param' : skopt.space.Real(1,5, prior = \"uniform\"),\n",
    "    'regression' : [RandomForestRegressor(random_state=2023)],\n",
    "    'regression__n_estimators': skopt.space.Integer(100, 2000),\n",
    "    'regression__max_depth': skopt.space.Integer(1, 50),\n",
    "    'regression__min_samples_split': skopt.space.Integer(2, 25)#,\n",
    "}\n",
    "\n",
    "\n",
    "param_bounds_en = {\n",
    "                 'feature_selection__split_param' : skopt.space.Real(1,5, prior = \"uniform\"),\n",
    "                 'regression' : [ElasticNet(random_state=2023)],\n",
    "                 'regression__alpha': skopt.space.Real(0.0001, 1.0, 'uniform'),\n",
    "                 'regression__l1_ratio': skopt.space.Real(0, 1.0, 'uniform')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a pipeline\n",
    "reg_RF = Pipeline([\n",
    "  #('scaler', StandardScaler()),  \n",
    "  ('feature_selection', SpearmanReducerCont()),\n",
    "  ('regression', RandomForestRegressor())\n",
    "]) \n",
    "\n",
    "# cv5 = KFold(5, shuffle=True, random_state=2023)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#try out models\n",
    "opt0 = skopt.BayesSearchCV(\n",
    "    reg_RF,\n",
    "    [(param_bounds_en, NUM_SEARCHES), (param_bounds_rf, NUM_SEARCHES)],\n",
    "    cv=split_indices_CV5_Tr,\n",
    "    scoring=SEARCH_SCORING_METRIC,\n",
    "    verbose=True,\n",
    "    random_state=2023,\n",
    "    n_jobs = 6\n",
    ")\n",
    "opt0.fit(X_Tr, Y_Tr)\n",
    "\n",
    "display(opt0.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_res = pd.DataFrame(opt0.cv_results_)\n",
    "cv_res\n",
    "cv_res.iloc[:, :].reset_index().loc[:, \"mean_test_score\"].plot()\n",
    "plt.grid()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_res_sorted = cv_res.sort_values(\"rank_test_score\")\n",
    "pd.DataFrame(list(cv_res_sorted[\"params\"]))\n",
    "#cv_res_sorted[[\"params\", \"mean_test_score\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save model trained on the whole training data set and optimal paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "idx_best_EN_model = cv_res[\"mean_test_score\"][:NUM_SEARCHES].argmax()\n",
    "idx_best_RF_model = cv_res[\"mean_test_score\"][NUM_SEARCHES:].argmax() + NUM_SEARCHES\n",
    "\n",
    "if SAVE_RESULTS:\n",
    "    os.makedirs(OUTDIR / \"regression\" / RADIOMICS_OPTION, exist_ok=True)\n",
    "    dst = OUTDIR / \"regression\" / RADIOMICS_OPTION / f\"Bayesian_results_{NUM_SEARCHES}_iterations_RFvsEN.xlsx\"\n",
    "    cv_res.to_excel(dst)\n",
    "    print(\"Saved hyperparams search to : \", dst)\n",
    "\n",
    "    \n",
    "    save_dst = OUTDIR / \"regression\" / RADIOMICS_OPTION\n",
    "    \n",
    "    # save optimal parameters as yaml: \n",
    "    dst = save_dst / \"SpearmanRed1_RF_opt_params.yml\"\n",
    "    data = {**cv_res.iloc[idx_best_RF_model, :].params}\n",
    "    if \"regression\" in data: \n",
    "        data.pop(\"regression\")\n",
    "    with open(dst, 'w') as outfile:\n",
    "        yaml.dump(data, outfile, default_flow_style=False)\n",
    "        print(\"saved params to \", dst)\n",
    "        \n",
    "\n",
    "    # save optimal parameters as yaml: \n",
    "    dst = save_dst / \"SpearmanRed1_EN_opt_params.yml\"\n",
    "    data = {**cv_res.iloc[idx_best_EN_model, :].params} # make copy to keep original dict unchanged\n",
    "    if \"regression\" in data: \n",
    "        data.pop(\"regression\")\n",
    "    with open(dst, 'w') as outfile:\n",
    "        yaml.dump(data, outfile, default_flow_style=False)\n",
    "        print(\"saved params to \", dst)\n",
    "        \n",
    "\n",
    "    #---- set best performing en/rf models\n",
    "    #create a pipeline\n",
    "    reg_RF = Pipeline([\n",
    "    #('scaler', StandardScaler()),  \n",
    "    ('feature_selection', SpearmanReducerCont()),\n",
    "    ('regression', RandomForestRegressor())\n",
    "    ]) \n",
    "    #Set params\n",
    "    np.random.seed(2023)\n",
    "    reg_RF.set_params(**cv_res.iloc[idx_best_RF_model, :].params)\n",
    "    reg_RF.fit(X_Tr, Y_Tr)\n",
    "    dst = save_dst / f\"SpearmanRed1_RF_opt.p\"\n",
    "    with open(dst, \"wb\") as fp:\n",
    "        pickle.dump(reg_RF, fp)\n",
    "        print(\"Saved model to \", dst)\n",
    "\n",
    "\n",
    "    #create a pipeline\n",
    "    reg_EN = Pipeline([\n",
    "    #('scaler', StandardScaler()),  \n",
    "    ('feature_selection', SpearmanReducerCont()),\n",
    "    ('regression', ElasticNet())\n",
    "    ]) \n",
    "    reg_EN.set_params(**cv_res.iloc[idx_best_EN_model, :].params)\n",
    "    reg_EN.fit(X_Tr, Y_Tr)\n",
    "    dst = save_dst / f\"SpearmanRed1_EN_opt.p\"\n",
    "    with open(dst, \"wb\") as fp:\n",
    "        pickle.dump(reg_EN, fp)\n",
    "        print(\"Saved model to \", dst)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt3-9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
