{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import numba\n",
    "from typing import Literal \n",
    "from glob import glob\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, r2_score, RocCurveDisplay\n",
    "# see https://stackoverflow.com/questions/60321389/sklearn-importerror-cannot-import-name-plot-roc-curve\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing  import StandardScaler\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from scipy.stats import ttest_ind\n",
    "from collections import defaultdict\n",
    "import seaborn as sns\n",
    "import skopt\n",
    "import time\n",
    "import re \n",
    "\n",
    "import radipop_utils \n",
    "import radipop_utils.visualization\n",
    "import radipop_utils.features\n",
    "from radipop_utils.features import SpearmanReducerCont\n",
    "import radipop_utils.utils\n",
    "from radipop_utils.utils import get_files_dict_by_regex_pattern\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# load user/ system specific env variables:\n",
    "from dotenv import dotenv_values, find_dotenv\n",
    "config = dotenv_values(find_dotenv())  # load environment variables as dictionary\n",
    "\n",
    "path = Path(os.path.abspath(radipop_utils.__file__))\n",
    "RADIPOP_PACKAGE_ROOT = path.parent.parent\n",
    "\n",
    "\n",
    "##------  You will likely need to change this \n",
    "DATA_ROOT_DIRECTORY = Path(config[\"DATA_ROOT_DIRECTORY\"])\n",
    "OUTDIR = DATA_ROOT_DIRECTORY / \"radiomics\" / \"Dataset125_LSS\" \n",
    "\n",
    "##-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# load features and combine with predicted values: \n",
    "\n",
    "def get_HVPG_values_and_radiomics_paths():\n",
    "\n",
    "    # TODO change to strict and rerun\n",
    "    df = pd.read_excel(RADIPOP_PACKAGE_ROOT / \"data\" / \"file_paths_and_hvpg_data.xlsx\")\n",
    "\n",
    "    DATA_ROOT_DIRECTORY = Path(config[\"DATA_ROOT_DIRECTORY\"])\n",
    "    base_path = DATA_ROOT_DIRECTORY / \"radiomics\" / \"Dataset125_LSS\" / \"radipop\"\n",
    "    dct_paths = get_files_dict_by_regex_pattern(base_path, regex_pattern=\"^Features_liver\", strict=False)\n",
    "    df_dirs_features_liver = pd.DataFrame.from_records({ 'id': dct_paths.keys(), 'radiomics-features: liver': dct_paths.values() })\n",
    "\n",
    "    dct_paths = get_files_dict_by_regex_pattern(base_path, regex_pattern=\"^Features_spleen\", strict=False)\n",
    "    df_dirs_features_spleen = pd.DataFrame.from_records({ 'id': dct_paths.keys(), 'radiomics-features: spleen': dct_paths.values() })\n",
    "\n",
    "    # Merge the DataFrames on the 'id' column\n",
    "    df = df.merge(df_dirs_features_liver, on='id', how='inner').merge(df_dirs_features_spleen, on='id', how='inner')\n",
    "    \n",
    "    # drop unnamed columns (index)\n",
    "    df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "    # TODO rm after strict \n",
    "    df['radiomics-features: liver'] = df['radiomics-features: liver'].apply(lambda x: x[0] if len(x)==1 else pd.NA)\n",
    "    df['radiomics-features: spleen'] = df['radiomics-features: spleen'].apply(lambda x: x[0] if len(x)==1 else pd.NA)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df = get_HVPG_values_and_radiomics_paths()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_combined_radiomics_features(df_paths: pd.DataFrame) -> pd.DataFrame:\n",
    "    dfs = []\n",
    "    df_paths = df_paths.reset_index(drop=True)\n",
    "    for i in range(len(df_paths)):\n",
    "\n",
    "        patientid = df_paths.loc[i, 'id']\n",
    "        file_r1 = df_paths.loc[i, 'radiomics-features: liver']\n",
    "        file_r2 = df_paths.loc[i, 'radiomics-features: spleen']\n",
    "\n",
    "        df_r1 = pd.read_excel(file_r1)  # these all have just a single row of data\n",
    "        df_r2 = pd.read_excel(file_r2)  \n",
    "        assert len(df_r1) == 1\n",
    "        assert len(df_r2) == 1\n",
    "\n",
    "        df_r1 = df_r1.loc[:, ~df_r1.columns.str.contains('^Unnamed')]\n",
    "        df_r2 = df_r2.loc[:, ~df_r2.columns.str.contains('^Unnamed')]\n",
    "\n",
    "        # Add prefixes to the columns\n",
    "        df_r1 = df_r1.add_prefix('liver: ')\n",
    "        df_r2 = df_r2.add_prefix('spleen: ')\n",
    "\n",
    "        combined_df = pd.concat([df_r1, df_r2], axis=1)\n",
    "        combined_df['id'] = patientid\n",
    "        \n",
    "        dfs.append(combined_df)\n",
    "        \n",
    "    df_radiomics = pd.concat(dfs, axis=0)\n",
    "\n",
    "    # Move column \"patient_id\" to be the first column\n",
    "    cols = list(df_radiomics.columns)\n",
    "    cols.insert(0, cols.pop(cols.index('id')))\n",
    "    df_radiomics = df_radiomics[cols].reset_index(drop=True)\n",
    "\n",
    "    return df_radiomics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rm external test set for now\n",
    "m = np.logical_or(df[\"set type\"] == \"Tr\", df[\"set type\"] == \"internal Ts\")\n",
    "                  \n",
    "df_  = df[m].dropna(subset=[\"radiomics-features: liver\", \"radiomics-features: spleen\"])\n",
    "df_radiomics = read_and_combined_radiomics_features(df_)\n",
    "\n",
    "\n",
    "df_radiomics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_radiomics\n",
    "\n",
    "df_merged = df.merge(df_radiomics, on='id', how='inner')\n",
    "\n",
    "# final filtered dataframe \n",
    "dff = df_merged.filter(regex=\"^id|^y|^set type|^Tr split|^liver|^spleen\")\n",
    "dff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m1 = dff[\"Tr split\"] == 0\n",
    "# m2 = ~m1 \n",
    "\n",
    "\n",
    "m1 = dff[\"set type\"] == \"Tr\"\n",
    "m2 = dff[\"set type\"] == \"internal Ts\"\n",
    "\n",
    "\n",
    "df_train  = dff[m1]\n",
    "df_test = dff[m2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_train)\n",
    "display(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract np arrays\n",
    "X_train, Y_train = df_train.filter(regex=\"^liver|^spleen\").values, df_train[\"y\"].values\n",
    "X_test, Y_test = df_test.filter(regex=\"^liver|^spleen\").values, df_test[\"y\"].values\n",
    "\n",
    "X_train.shape\n",
    "\n",
    "# Normalize\n",
    "from sklearn.preprocessing import Normalizer\n",
    "transformer = Normalizer().fit(X_train)  # fit on trainig data only\n",
    "\n",
    "\n",
    "X_train = transformer.transform(X_train)\n",
    "X_test = transformer.transform(X_test)\n",
    "\n",
    "# I will not normalize the targets for now. They dont have vastly different magnitude anyhow. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot dendrogram\n",
    "corr = spearmanr(X_train).correlation\n",
    "\n",
    "# Ensure the correlation matrix is symmetric\n",
    "corr = (corr + corr.T) / 2\n",
    "np.fill_diagonal(corr, 1)\n",
    "\n",
    "# plt.matshow(corr)\n",
    "# plt.show()\n",
    "\n",
    "# We convert the correlation matrix to a distance matrix before performing\n",
    "# hierarchical clustering using Ward's linkage.\n",
    "distance_matrix = 1 - np.abs(corr)\n",
    "dist_linkage = hierarchy.ward(squareform(distance_matrix))\n",
    "plt.figure()\n",
    "dendro = hierarchy.dendrogram(\n",
    "    dist_linkage, no_labels=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decide on cut parameters for dendrogram\n",
    "split_params = [0.5, 0.75, 1, 5, 7.5, 10]\n",
    "for split_param in split_params:\n",
    "    selector = SpearmanReducerCont(split_param=split_param)\n",
    "    print(f\"Selected features at height {split_param}:\", len(selector.fit(X_train, Y_train).selected_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bounds for hyperparameters\n",
    "param_bounds_rf = {\n",
    "    'feature_selection__split_param' : skopt.space.Real(1,5, prior = \"uniform\"),\n",
    "    'regression' : [RandomForestRegressor(random_state=2023)],\n",
    "    'regression__n_estimators': skopt.space.Integer(100, 2000),\n",
    "    'regression__max_depth': skopt.space.Integer(1, 50),\n",
    "    'regression__min_samples_split': skopt.space.Integer(2, 25)#,\n",
    "}\n",
    "\n",
    "\n",
    "param_bounds_en = {\n",
    "                 'feature_selection__split_param' : skopt.space.Real(1,5, prior = \"uniform\"),\n",
    "                 'regression' : [ElasticNet(random_state=2023)],\n",
    "                 'regression__alpha': skopt.space.Real(0.0001, 1.0, 'uniform'),\n",
    "                 'regression__l1_ratio': skopt.space.Real(0, 1.0, 'uniform')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a pipeline\n",
    "reg = Pipeline([\n",
    "  #('scaler', StandardScaler()),  \n",
    "  ('feature_selection', SpearmanReducerCont()),\n",
    "  ('regression', RandomForestRegressor())\n",
    "]) \n",
    "\n",
    "cv5 = KFold(5, shuffle=True, random_state=2023)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try out models\n",
    "opt0 = skopt.BayesSearchCV(\n",
    "    reg,\n",
    "    [(param_bounds_en, 10), (param_bounds_rf, 10)],\n",
    "    cv=cv5,\n",
    "    scoring=\"r2\",\n",
    "    verbose=True,\n",
    "    random_state=2023,\n",
    "    n_jobs = 6\n",
    ")\n",
    "opt0.fit(X_train, Y_train)\n",
    "\n",
    "display(opt0.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_res = pd.DataFrame(opt0.cv_results_)\n",
    "cv_res\n",
    "cv_res.iloc[11:, :].reset_index().loc[:, \"mean_test_score\"].plot()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_res.to_excel(\"Bayesian_results_10_iterations_RFvsEN.xlsx\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a pipeline\n",
    "reg = Pipeline([\n",
    "  #('scaler', StandardScaler()),  \n",
    "  ('feature_selection', SpearmanReducerCont()),\n",
    "  ('regression', RandomForestRegressor())\n",
    "]) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set params\n",
    "np.random.seed(2023)\n",
    "print(opt0.best_params_)\n",
    "reg.set_params(**opt0.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#supp data - training data performance\n",
    "\n",
    "# set best performing en model (rf model has already been set)\n",
    "#create a pipeline\n",
    "reg_EN = Pipeline([\n",
    "  #('scaler', StandardScaler()),  \n",
    "  ('feature_selection', SpearmanReducerCont()),\n",
    "  ('regression', ElasticNet())\n",
    "]) \n",
    "\n",
    "reg_EN.set_params(**cv_res.iloc[5, :].params)\n",
    "\n",
    "#run 5 fold cv\n",
    "rf_train_res = np.array([])\n",
    "en_train_res = np.array([])\n",
    "obs = np.array([])\n",
    "\n",
    "for train, test in cv5.split(X_train):\n",
    "    \n",
    "    #rf\n",
    "    reg.fit(X_train[train], Y_train[train])\n",
    "    rf_train_res = np.append(rf_train_res, reg.predict(X_train[test]))\n",
    "    \n",
    "    #en\n",
    "    reg_EN.fit(X_train[train], Y_train[train])\n",
    "    en_train_res = np.append(en_train_res, reg_EN.predict(X_train[test]))\n",
    "    \n",
    "    #obs\n",
    "    obs = np.append(obs, Y_train[test])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_training = pd.DataFrame({\"True_HVPG\" : obs, \n",
    "                             \"RF_HVPG\" : rf_train_res,\n",
    "                             \"EN_HVPG\" : en_train_res})\n",
    "\n",
    "display(res_training)\n",
    "# os.makedirs(OUTDIR / \"model_training\", exists_ok=True)\n",
    "# res_training.to_excel(OUTDIR / \"model_training/CV_results_training_cohort.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"/home/cwatzenboeck/data/cirdata/tabular_data/Celine_FINAL_RADIOPOP_DATA_with LRE Death_220708.xlsx\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = df[[\"ID\", \"BL_HVPG_corrected (ohne Kollat., inkor. Messungen)\"]].rename(columns={'BL_HVPG_corrected (ohne Kollat., inkor. Messungen)': \"y\"})\n",
    "m = dft[\"y\"] <= 2\n",
    "dft[m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt3-9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
