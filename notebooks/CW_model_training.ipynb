{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CW_model_training.ipynb \n",
    "\n",
    "This is based on the original notebook by the main author of the paper (`RADIPOP_model_training.ipynb`).\n",
    "Since I need to reuse it on new data, I might as well clean it up a bit. \n",
    "\n",
    "\n",
    "However, currently it is not finished... #TODO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import numba\n",
    "from typing import Literal, Union\n",
    "from glob import glob\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, r2_score, RocCurveDisplay\n",
    "# see https://stackoverflow.com/questions/60321389/sklearn-importerror-cannot-import-name-plot-roc-curve\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing  import StandardScaler\n",
    "\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from scipy.stats import ttest_ind\n",
    "from collections import defaultdict\n",
    "import seaborn as sns\n",
    "import skopt\n",
    "import time\n",
    "import re \n",
    "\n",
    "import radipop_utils \n",
    "import radipop_utils.visualization\n",
    "import radipop_utils.features\n",
    "from radipop_utils.features import SpearmanReducerCont\n",
    "import radipop_utils.utils\n",
    "from radipop_utils.utils import get_files_dict_by_regex_pattern\n",
    "\n",
    "import radipop_utils.data\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# load user/ system specific env variables:\n",
    "from dotenv import dotenv_values, find_dotenv\n",
    "config = dotenv_values(find_dotenv())  # load environment variables as dictionary\n",
    "\n",
    "path = Path(os.path.abspath(radipop_utils.__file__))\n",
    "RADIPOP_PACKAGE_ROOT = path.parent.parent\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##------  You will likely need to change this \n",
    "DATA_ROOT_DIRECTORY = Path(config[\"DATA_ROOT_DIRECTORY\"])\n",
    "OUTDIR = DATA_ROOT_DIRECTORY / \"radiomics\" / \"Dataset125_LSS\" \n",
    "DATASET = \"Dataset125_LSS\"\n",
    "RADIOMICS_OPTION = \"radipop_111\"\n",
    "NUM_SEARCHES = 20\n",
    "SEARCH_SCORING_METRIC = \"r2\"  # \"neg_root_mean_squared_error\"  \"r2\"\n",
    "SAVE_RESULTS = False\n",
    "##-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the the data: \n",
    "- load radiomics and HVPG values \n",
    "- utilize our custom split (previously defined and stratified on sex, scanner, status)\n",
    "- normalized the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(df_Tr)=298, len(df_eTs)=50, len(df_iTs)=50\n"
     ]
    }
   ],
   "source": [
    "# load features and combine with predicted values: \n",
    "\n",
    "df_Tr, df_iTs, df_eTs = radipop_utils.data.load_HVPG_values_and_radiomics(DATASET=DATASET, RADIOMICS_OPTION=RADIOMICS_OPTION, DATA_ROOT_DIRECTORY=DATA_ROOT_DIRECTORY)\n",
    "print(f\"{len(df_Tr)=}, {len(df_eTs)=}, {len(df_iTs)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(df_Tr)\n",
    "# display(df_iTs)\n",
    "# display(df_eTs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_indices_CV5_Tr = radipop_utils.data.extract_CV_indices(df_Tr)\n",
    "\n",
    "X_Tr, Y_Tr, X_iTs, Y_iTs, X_eTs, Y_eTs = radipop_utils.data.preprocess_data(df_Tr, df_iTs, df_eTs, normalize_X=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot dendrogram\n",
    "corr = spearmanr(X_Tr).correlation\n",
    "\n",
    "# Ensure the correlation matrix is symmetric\n",
    "corr = (corr + corr.T) / 2\n",
    "np.fill_diagonal(corr, 1)\n",
    "\n",
    "# plt.matshow(corr)\n",
    "# plt.show()\n",
    "\n",
    "# We convert the correlation matrix to a distance matrix before performing\n",
    "# hierarchical clustering using Ward's linkage.\n",
    "distance_matrix = 1 - np.abs(corr)\n",
    "dist_linkage = hierarchy.ward(squareform(distance_matrix))\n",
    "plt.figure()\n",
    "dendro = hierarchy.dendrogram(\n",
    "    dist_linkage, no_labels=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features at height 0.5: 234\n",
      "Selected features at height 0.75: 150\n",
      "Selected features at height 1: 104\n",
      "Selected features at height 2.75: 29\n",
      "Selected features at height 5: 9\n",
      "Selected features at height 7.5: 6\n",
      "Selected features at height 10: 3\n"
     ]
    }
   ],
   "source": [
    "#decide on a rought range for the cut parameters for dendrogram\n",
    "split_params = [0.5, 0.75, 1, 2.75,  5, 7.5, 10]\n",
    "for split_param in split_params:\n",
    "    selector = SpearmanReducerCont(split_param=split_param)\n",
    "    print(f\"Selected features at height {split_param}:\", len(selector.fit(X_Tr, Y_Tr).selected_features))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit on `Tr` data with CV and estimate best model + hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bounds for hyperparameters\n",
    "param_bounds_rf = {\n",
    "    'feature_selection__split_param' : skopt.space.Real(1,5, prior = \"uniform\"),\n",
    "    'regression' : [RandomForestRegressor(random_state=2023)],\n",
    "    'regression__n_estimators': skopt.space.Integer(100, 2000),\n",
    "    'regression__max_depth': skopt.space.Integer(1, 50),\n",
    "    'regression__min_samples_split': skopt.space.Integer(2, 25)#,\n",
    "}\n",
    "\n",
    "\n",
    "param_bounds_en = {\n",
    "                 'feature_selection__split_param' : skopt.space.Real(1,5, prior = \"uniform\"),\n",
    "                 'regression' : [ElasticNet(random_state=2023)],\n",
    "                 'regression__alpha': skopt.space.Real(0.0001, 1.0, 'uniform'),\n",
    "                 'regression__l1_ratio': skopt.space.Real(0, 1.0, 'uniform')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a pipeline\n",
    "reg_RF = Pipeline([\n",
    "  #('scaler', StandardScaler()),  \n",
    "  ('feature_selection', SpearmanReducerCont()),\n",
    "  ('regression', RandomForestRegressor())\n",
    "]) \n",
    "\n",
    "# cv5 = KFold(5, shuffle=True, random_state=2023)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cwatzenboeck/anaconda3/envs/pyt3-9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.013e+00, tolerance: 4.617e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/cwatzenboeck/anaconda3/envs/pyt3-9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.107e-01, tolerance: 3.536e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/cwatzenboeck/anaconda3/envs/pyt3-9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.034e-01, tolerance: 4.095e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/cwatzenboeck/anaconda3/envs/pyt3-9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.007e+00, tolerance: 4.399e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/cwatzenboeck/anaconda3/envs/pyt3-9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.212e+00, tolerance: 7.005e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cwatzenboeck/anaconda3/envs/pyt3-9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.510e+02, tolerance: 3.536e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/cwatzenboeck/anaconda3/envs/pyt3-9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.858e+02, tolerance: 4.095e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/cwatzenboeck/anaconda3/envs/pyt3-9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.123e+03, tolerance: 7.005e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/cwatzenboeck/anaconda3/envs/pyt3-9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.687e+02, tolerance: 4.399e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/cwatzenboeck/anaconda3/envs/pyt3-9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.477e+02, tolerance: 4.617e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cwatzenboeck/anaconda3/envs/pyt3-9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.344e+02, tolerance: 4.617e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/cwatzenboeck/anaconda3/envs/pyt3-9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.621e+03, tolerance: 7.005e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/cwatzenboeck/anaconda3/envs/pyt3-9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.928e+02, tolerance: 4.399e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/cwatzenboeck/anaconda3/envs/pyt3-9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.666e+02, tolerance: 3.536e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/cwatzenboeck/anaconda3/envs/pyt3-9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.119e+02, tolerance: 4.095e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cwatzenboeck/anaconda3/envs/pyt3-9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.601e+03, tolerance: 4.095e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/cwatzenboeck/anaconda3/envs/pyt3-9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.516e+03, tolerance: 7.005e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/cwatzenboeck/anaconda3/envs/pyt3-9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.073e+03, tolerance: 3.536e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/cwatzenboeck/anaconda3/envs/pyt3-9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.231e+03, tolerance: 4.399e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/cwatzenboeck/anaconda3/envs/pyt3-9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.463e+03, tolerance: 4.617e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('feature_selection__split_param', 1.0),\n",
       "             ('regression',\n",
       "              ElasticNet(alpha=0.9435871670614078, l1_ratio=1.0, random_state=2023)),\n",
       "             ('regression__alpha', 0.9435871670614078),\n",
       "             ('regression__l1_ratio', 1.0)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#try out models\n",
    "opt0 = skopt.BayesSearchCV(\n",
    "    reg_RF,\n",
    "    [(param_bounds_en, NUM_SEARCHES), (param_bounds_rf, NUM_SEARCHES)],\n",
    "    cv=split_indices_CV5_Tr,\n",
    "    scoring=SEARCH_SCORING_METRIC,\n",
    "    verbose=True,\n",
    "    random_state=2023,\n",
    "    n_jobs = 6\n",
    ")\n",
    "opt0.fit(X_Tr, Y_Tr)\n",
    "\n",
    "display(opt0.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiIAAAGdCAYAAAAvwBgXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA69klEQVR4nO3de3xcdZ3/8feZ25lMmqSXtE1K06blUu63VqEsyM1WWl1x+cGPWtcHrsiK2l2w7rp0XaV12QW1oqusqD92hfVnf6A/vOxPUZv9AQXF/ijYSotcWtrS0ntamkkzyVzP74+ZM5k0aZJJ5sxJz3k9H488kkwmZ85nTuabz3y+N8OyLEsAAAAuCLh9AgAAwL9IRAAAgGtIRAAAgGtIRAAAgGtIRAAAgGtIRAAAgGtIRAAAgGtIRAAAgGtCbp/AYHK5nPbu3au6ujoZhuH26QAAgGGwLEudnZ2aNm2aAoHBax5jOhHZu3evWlpa3D4NAAAwArt379b06dMHvc+YTkTq6uok5QOpr6+v6LHT6bTWrl2rhQsXKhwOV/TYY4kf4vRDjBJxeg1xeocfYpTKizMej6ulpaX4f3wwYzoRsbtj6uvrHUlEYrGY6uvrPf+H4/U4/RCjRJxeQ5ze4YcYpZHFOZxhFQxWBQAAriERAQAAriERAQAAriERAQAAriERAQAAriERAQAAriERAQAAriERAQAAriERAQAAriERAQAAriERAQAAriERAQAArhnTm94BcF53Kqv/euWA/rD7qMKhgCLBgMxwQGYoKDMUyH+ES74OBRUJ5d/DZLI5ZXKW0tmcMllLmVxO6ZLP2ZylTDanQMDQ/NmTNHvyOJejBTDWkIjgpJTLWdof79GuIwntONSpTQcMXZvOenrny0rK5iyt335YP9m4R7/asl/HkpmqPO6cqXW67twmLTqvSXOm1g1rZ04A3ubLRKSzJ63X93Xo1aOGjC37lUhbivekFe/OFD6nFe/JFD6n1dmTUTKT04RYWJPGmZo8zlTjuIgax5maZH9dl7990riIYpHRPa2WZSmd7X2XmcrmlMn1fh0KGKqPhlUXDSkU9G7vWlcyo91vJ7TrcEK7jvT9eOtIt1LZXMm9g5q75YD++ztnuna+I9GTzupYMv/3lSr5SGay+c/ZnJLpnFLZnLqTKf2x3dDs/Z06o7lBZihY1mNZlqU/7ovrZ5v26meb9uhAPFn82Snja7Tg7KkKBgwlM1kl0zklC+eRzOQK3xe+LtwuSeFAQKGgoVAgoHDQUCgYUChgKBzse/vRRFobdh7Rawc69dqBTv3L/92qWY21es85TVp0bpPOn95AUgL4lC8Tked3HNGtj7wgKSi98tKwf+9IV0pvHOoa8n6xSFA14eH/k8hZljJZS+mcXd62hv27NeGg6qIh1dfkE5O6aFj1JZ9rIwEdPGRoyptva9bkek2pMxUIVK/BtyxLb73drU27j2pHe5cSqax60ll1p7LqTmd7vy+5rTuVVSKVUbxn8HfpoYCh6RNq1NmT0eGulA4dSw56/5HY0d6lB5/ephsunq5LZ0+q2HGzOUsPPr1N33hym1KZ3NC/UBTUI1t/p2DAUOukmOY01en0KXWa01SnM6bWqXVSrF9yuudot362aY9+unGPXj9wrHh7Q01Y7z2/WX920SmaO2OC438XRxMp/dcrB/WrLfv0zNZ27Wjv0rfXvaFvr3tDp4yvyScl5zXpvGa6b+CuQ51JvX6gU5I0td7UlPqo6swQybJDfJmITKiNaFpDVEp3a9rkCRofi6g+GlZ9Tf6fd/5zWPU1oULlIaxIKKDDXUm1H0vp8LGk2o8l1d6Z0uGupA4dS6m9M39bMpNTIpX/B1tJ4WDhXWbAUCZnFY/fXfgnfrBzsH/CQf3PbRskSZFQQNPH12j6xJhaJtSoZWJMLRNiml74ekIsPKoXW0cirU1vHdUfdh/Vpt35z4e7UiM+3vhYWDMmxvp/TIqpuaFGwYChux7/gx7d8JaSZf1DH54fvbBbP3zhLf3oxbf08XedquULziiOjxipg/EeffqHm/TbbYeLt0WCAUUKYzAioeO+DtqfDe3e367D6bDiPRm9cairkBjv73Oc2ZNrNaepTjMnxvT/dhzR/9txpPfnoYDefdYUfeDCU3TlnMllV1VGY3wsohvnTteNc6frWDKjp149qF9t2a+nXjuoPUe79e+/3aF//+0OTR4X0bRIQL9JvayGmsiASXZdNKSGwu2xSEiJVEZHE2l1dKd1tDv/uSORyn9/3O096awMSTIMBQzJkGQYhgxJASN/g/11ICBNqjXVPD6qU8bXqLmhRtPGRzWtoUbjR/ha6UlnFe9O63Bnt/YnpLfe7lZtTVbRcFDRUFDhoDHkcXvSWb2dSOlIV0pHE2kd6UoVv3+7K6UjibQiwYBOGR9V8/gaTRtfo2kN+a/HmZVv9rtTWb31dr5auftIQrvf7i5+fSDeo4gV1E8O/16tjeM0c1JMMyfFNGNirVom1gz5N5jLWdoX79Gb7V3aeTihN4906c32hN48ktBbRxKqrwlr9uRazW6s1ezJ4/JfTx6n5vrokMl1KpPTG4eO6ZV9cb26v1Ov7IvrlX2dah/gTU0sEtTU+qim1JmaWh/V1Pr85yn1UU2KBbU/Ib28N660ZSiRyqo7lVFXMqtEuvfr/JuvjBLJrFLZnCxJsvJvRi37s/Jv4Eq/l6TaSKjwOggVK+J1x31uKHmtBKv4hnO0DMuyhv/2u8ri8bgaGhrU0dGh+vr6ih47nU7riSee0OLFiys2rsCyLHWlsmrvTJb9T9FONPIf+RJ3pFje7t8wZbI5HUtmit1JnT29nzvt77vTOtKV1OY33lJ3IKZ98aSyQ1RbasJBTayNaNK4iCbVRjSxNt/1lL/NLNyW/3l9TVjbD3Vp06639Ye3OopVj4FiO7u5Xmc21WtcNKSacFA1kaCi4XzlKGZ/Xagk5X8e0OS6qBpqhr42K3+2WQ//bpc+fsUsrXjv2WU970P5ws+26D9+92bx+3NPqdfXb75Ip00Z2bv2da8f0md+uEntx1KqCQf1xevP0Y1zpw/rH5r9N7to0SId6c7p9QOdxY/XDhzT1gOdAybAhiFdMmui/uyiU3Tduc3Dek6rqSed1TOvH9KvtuxX2ysH1DlEJWysqAkH1VxISqaNj6q5kJzEuzP5RKg7rY7uVMnXdiI0eNsQMKRoYXBwNBwsfh0M5Lu43k6kRvVGpz4ayicm42vU3BDVtPE1mlofVcCQcsV/ilbx65yVb9tyud7bjibS+W7TIwntPtI94D/u4TAMqbk+qhmTYpo5sVYzJsVUGwnqzSP5Ltmdh7u0u1837PDUhINqbazV7Mm1OrWQpDTEwtp6oFOv7MsnHW8cOqZ0tn+baBhS66RahQKGDsR7hqzOjjWRUECzG2t1+tQ6nT5lnM6YOk6nTanTzEkxhUfRnV/O/81y/n/7siLiFMMwNM4MOfKO43ihYEDjYxGNj0UGvV/+D2eXFi9+l4xAUPs6egrvWPINSP5z/h3Moc6kutNZ7TnarT1Hu0d8bq2TYrqgZbwuLHyc1VyvaBldVeWy31H1ZCpbhZKkZOGfxhWnN2rLng5t2RPX+775rD63+Cz9+aUzh/2OOJ3N6atrX9e3170hSTqzqU4PLL14RAmNYRhqaoiqqSGqd50xuXh7Lmdpz9HuQnJyTNsPHdPsyeN0/YXTNG18TdmPUy3RcFALz2nSwnOalMrk9NutB/WLZ55Xy+w5SqRz+XFbPZlict1Z/L7vP/VYJKiGmrAaasIaHyt8romoofC1fXtNOCjLUvGdZ67wttS+zX53aknK5nI61JnU3qM92tfRXfzcfiyl7nRW2w91afswumuPZxj5hCCdSisXCPaJI2eppKqaPuExQgFDE2ojmhiLaHwsrIm1EU2ojWhCLKwJsYiSmZz2Hu3W3qPd2tfRo71Hu/Nj33oyiu/v1Kv7O8s+78HUmaF8hXVijVom5KuWLRNiaqwN6ZdP/kZNp5+rPUeTevNwopBodKkrldXejh7t7ejR+u1HTnjscNBQy4RYoZpSq5mTYmqdlK+ovJ1Ia/uhY9peqBBubz+mXYcT6k5nCxWO+ODnHQ3prKZ6ndVcpzOb63VWc73mTK1TTaS3zUqkMjoYT+pAvEcHOpM6GO/RgXiP9tu3dfToYEeX6mJRxSJBxSKhfBd9JKja0q/NUPHNVzgYUMCQAgHjuApd4XPha8PI/y12JTN93mgO9Oazsyej7nR+fNmrA1zjcNDQrJIE5fQpdTp96ji1TqoddaV3NEhEfCQUDBQaitiAP+9JZ3Ug3qPDXSkdPpbSkUJX1JGu/Ef7saSOFH+WUiqbH8B7Ycv4YuJxwfTxmlA7eHJUaWY4UDj/ynfN2MnNlWdM1uqbLtDf/OgPenZruz7/s5f11GuH9KX/dr4m15mDHuOttxP66/+1Ub/fdVSS9OeXztA/vPfsiidngYBRvL7XnjW1oseulkgooMtPm6T465YWXzV7yHddqUxOiVRGsUioqg1pTzqr/YV/7nsLn/d1dCvenVF9TUgNNZFi8nN8clRfE1adGVI2mym8u3yPQqFQ70DgdFY9hcHBPemcejL5cVTZnKXxsULiURse0ZiFY8mM9hXOeV8hSdnb0aODnUlZlpXvjjLy3VJGydeBgArf528bZ4Y0o/C31jIhn3w01AzcVZVOp7V9vKXF72jpcz0ty1L7sZR2HenKJyeFQemJVEYzJuYTjtZC0jFtfM2gXQ3vaJ3Y9zGzOe0+ksgniu3Hignj0e6UTpsyTmc11ReSjjqdMr5myOcxFgmptTGk1sbaAX/eWym40vWZe+lsTvs7erT1YKe2Hjim1w8c07aDndp68JgSqaxeL9xW6vzpDfrPZZe7dMYkIigRDQcL7zYGfrGVsqz8OJVYJOj6AK5oIRFJpitfEekpHDMazvcPP/IX79TDz+3Ufb96VU++elDXff0ZffnG80/4j/9XW/bps//7JcV7MqqLhvTl/3a+Fp3XXPHz9Kv8eJrqJr5S/u+htbH2hP+YhiNb8udqGEaxG0YOdp2NM0P5d8NT6xx7jOEyDEOT60xNrjM1d+bEoX+hDOFgoDBeZJykkzMpH6lwyRvOa87sjT2Xs7S3o1tbDx7TtgPHtPVgZyFJOaZTXV7fh0QEI2IYhmqr0AU1HNFi14wDFZFClcUsvNsOBAx99PJZuuy0Sbrz0U16dX+nbn3kBf35pTP0ucVnF8u5Pems/ukXr+j76/PjSy5sGa9vfvCiE1ajAMBJgYCh6RNimj4hpqvnTCneblmWuh14E1cO7y5CAd8oVkQcGCNSWhEpdWZTvX76qT/RrZfPkiT9z/W79L5vPqstezr0xqFj+rNvPVdMQj5+5Wz96Pb5JCEAxhzDMEa99tVoVSUR+da3vqVZs2YpGo1q7ty5evbZZ6vxsPAJe7Bq0pExIvljDjSeIxoO6vPvO1vfv/WdmlJn6o1DXfrAv/5W7/vGb/TKvrgm1Ub08F+8QysWnTWqkeoA4GWOt46PPfaY7rzzTn3uc5/Txo0bdcUVV2jRokXatWuX0w8Nn7ArIk50zSSLFZETv1SuOH2yfn3nu3TdOU3K5PJlzstOnaRf3nGFriopgQIA+nO8HnP//ffr1ltv1cc+9jFJ0te//nX9+te/1oMPPqh7773X6YeHD9jjN3ocHqw6mAm1ET345xfrl1v2K96d1k3zWk6qBYUAwC2OJiKpVEovvvii7rrrrj63L1y4UM8991y/+yeTSSWTvQvjxOP5+d/pdFrp9Inn04+EfbxKH3es8UOcISO/IFFPOlvxOO1BXCFZwzr2gjMbJUm5bEa5CudFfriWEnF6jR/i9EOMUnlxlvNcOJqItLe3K5vNaurUvtOnpk6dqv379/e7/7333qtVq1b1u33t2rWKxZwZ6NfW1ubIcccaL8e5s1OSQjra2aUnnniiosc+lghKMvT8736jXWNkrKmXr2Up4vQWP8Tphxil4cWZSCSGfbyqDJU9fp0Jy7IGXHtixYoVWr58efH7eDyulpYWLVy40JEl3tva2rRgwQLXF6Bxkh/i3PLW2/ralg0yQqYWL76qose+64X/kpTTgmuvUssEdzMRP1xLiTi9xg9x+iFGqbw47R6N4XA0EWlsbFQwGOxX/Th48GC/KokkmaYp0+y/SmU4HHbs4jp57LHEy3GOq8kvaJXM5Coao2VZxQGw42rMMfP8eflaliJOb/FDnH6IURpenOU8D47OmolEIpo7d26/Mk5bW5suu+wyJx8aPlKcvlvhdURS2ZzsLSGruUstAPiJ410zy5cv14c//GHNmzdP8+fP13e/+13t2rVLt99+u9MPDZ+wZ82ks5ayOatis1VK964ZbPouAGDkHE9Ebr75Zh0+fFhf/OIXtW/fPp177rl64oknNHPmTKcfGj5RmiT0pLMVW3reXkPEMKQIC5IBgCOqMlj1k5/8pD75yU9W46HgQ9GSbpNKJiJ2RSQacn9jPwDwKt7m4aQXCBgKFtYSSVZwddWezNCrqgIARocWFp4QKfwlV3J11eGuqgoAGDkSEXhCuJiIVK4ikhxkwzsAQGWQiMATQnYiUsEpvHZFxJ6VAwCoPFpYeELYka4ZKiIA4DQSEXiCnYgkK9g1Q0UEAJxHCwtPcKYiwmBVAHAaiQg8IRxwYvqu3TXDywQAnEILC09wYvpukooIADiORASeEHKya4YN7wDAMSQi8ITiGJFKds2k6ZoBAKfRwsITnBismszQNQMATiMRgSc4sbKqfSyTRAQAHEMiAk8oriPiwMqqdM0AgHNoYeEJkcL03YpWRArjTUwGqwKAY0hE4AkhI/856ciCZrxMAMAptLDwhLCDm94xfRcAnEMiAk9wYrBqkk3vAMBxJCLwBEf2msnQNQMATqOFhSf0zpqhIgIAJxMSEXiCE3vNUBEBAOfRwsITwsXpu5UfrMr0XQBwDokIPCHk4MqqVEQAwDm0sPAEJ1dWpSICAM4hEYEnVHr6rmVZxYGvDFYFAOeQiMATIhWuiJTOvqFrBgCcQwsLT7BzhXTWUjZnjfp4pYNeqYgAgHNIROAJpUWLSsycsbt4ggFD4SAvEwBwCi0sPCFU4UTE7uKJhniJAICTaGXhCQFDCgfzW/D2VGB11R5WVQWAqiARgWfYSUNlumbsVVVJRADASSQi8Ay7GyVZgSm8vWuI8BIBACfRysIzTLsiUoEpvHb3jklFBAAcRSICz7ArIpXtmuElAgBOopWFZ5jhynfNRFneHQAcRSICz7CThopM32XDOwCoClpZeIZdEanMGBFmzQBANZCIwDPsikglumaSrCMCAFVBIgLPsLtRGKwKACcPWll4Ru/03QoMVs3Y64hQEQEAJ5GIwDPMik7ftdcR4SUCAE6ilYVn9K4jwvRdADhZkIjAMyq71wyDVQGgGhxNRP7pn/5Jl112mWKxmMaPH+/kQwHFrplkBceIMFgVAJzlaCubSqV000036ROf+ISTDwNI6q1eJCuyoBnriABANYScPPiqVaskSQ8//LCTDwNIKpm+W4kFzVhZFQCqwtFEpFzJZFLJZLL4fTwelySl02ml0+mKPpZ9vEofd6zxQ5x2bCHDkiQlkplRx9uTzhSOOXaeOz9cS4k4vcYPcfohRqm8OMt5LgzLsqwRn9UwPfzww7rzzjt19OjRQe+3cuXKYhWl1Jo1axSLxRw6O3jFC4cMfX9bUKfX57TsnNGNE1n9UlC7uwz95ZlZnTPB8ZcIAHhKIpHQ0qVL1dHRofr6+kHvW3ZF5ETJQqkNGzZo3rx55R5aK1as0PLly4vfx+NxtbS0aOHChUMGUq50Oq22tjYtWLBA4XC4osceS/wQpx3jOy6+QN/ftkXjGiZo8eJLRnXMb277rdTVpcvnv1PzZ0+q0JmOjh+upUScXuOHOP0Qo1RenHaPxnCUnYgsW7ZMS5YsGfQ+ra2t5R5WkmSapkzT7Hd7OBx27OI6eeyxxA9x1kYjkqRkxhp1rMlsrnBMc8w9b364lhJxeo0f4vRDjNLw4izneSg7EWlsbFRjY2O5vwY4rnf6LoNVAeBk4ehg1V27dunIkSPatWuXstmsNm3aJEk67bTTNG7cOCcfGj7Uu6BZBVdWZfouADjK0UTkC1/4gh555JHi9xdddJEk6amnntJVV13l5EPDhypZEUmysioAVIWjdeeHH35YlmX1+yAJgROK64iMsiKSzVlKFcaI2PvXAACcQSsLzzBDldlrprSiQkUEAJxFIgLPsCsimZylTHbkVZFkSUWFRAQAnEUiAs+IhnqThtFsfGcvER8OGgoGjFGfFwDgxEhE4BlmyXiO0XTP2GNMzBDVEABwGokIPCMQMBQJ2RvfjaIiUpy6y8sDAJxGSwtPsasio6uIZAvHoiICAE4jEYGn9C5qNvquGSoiAOA8Wlp4SiXWErEHqzJjBgCcRyICT7FnzoxmddUky7sDQNWQiMBT7OQhOYqKiD31l64ZAHAeLS08pbdrZvSDVaMMVgUAx5GIwFOKy7yPomumhw3vAKBqSETgKRUZrFqcvsvLAwCcRksLTzErOH3XpCICAI4jEYGn9M6aqcT0XV4eAOA0Wlp4SkUHq1IRAQDHkYjAU3pXVh3NGJHCYFVmzQCA40hE4CmV2GsmyaZ3AFA1tLTwlOKCZqNZWTXD9F0AqBYSEXhKJafvUhEBAOfR0sJTKlERYdM7AKgeEhF4ij3AtBKDVVnQDACcR0sLTzErOH2XBc0AwHkkIvCU4l4zbHoHACcFEhF4SmUGq9qzZnh5AIDTaGnhKcUFzUY1fZfBqgBQLSQi8JTirJmKVERIRADAaSQi8BS7O2V0C5qxjggAVAstLTxltNN3szlL6azV51gAAOeQiMBTRjt9t/T3TCoiAOA4Wlp4il3FyOQsZbLlV0VKExEqIgDgPBIReErpANOezAgSkcLvRIIBBQJGxc4LADAwEhF4Sumy7CPpnuldVZWXBgBUA60tPCUQMBQJ2TNnRt41w9RdAKgOEhF4TjQ08gGrrKoKANVFawvPKa6uOoJEJMk+MwBQVSQi8BxzFPvN2N05dM0AQHWQiMBz7GpGchSDVemaAYDqoLWF54xm4zv7d0y6ZgCgKkhE4DnF/WZG0DXDYFUAqC5aW3jOqCoixXVEqIgAQDWQiMBzzFFsfFesiNA1AwBVQSICzxnNxncMVgWA6nKstd25c6duvfVWzZo1SzU1NTr11FN19913K5VKOfWQgKTeasaIKiIZVlYFgGoKOXXgV199VblcTt/5znd02mmnacuWLbrtttvU1dWl1atXO/WwQLGaMbIFzRisCgDV5Fgict111+m6664rfj979my99tprevDBB0lE4Ci7mjGSvWaSGVZWBYBqciwRGUhHR4cmTpx4wp8nk0klk8ni9/F4XJKUTqeVTqcrei728Sp93LHGD3EeH2OkUMxIJMv/u0kkM5KkcHDsPWd+uJYScXqNH+L0Q4xSeXGW81wYlmVZIz6rMrzxxhu6+OKL9dWvflUf+9jHBrzPypUrtWrVqn63r1mzRrFYzOlThEf8+i1DT+wOav6UnJacWl5V5N9fC+gPRwK6cVZWVzRV5aUBAJ6TSCS0dOlSdXR0qL6+ftD7lp2InChZKLVhwwbNmzev+P3evXt15ZVX6sorr9RDDz10wt8bqCLS0tKi9vb2IQMpVzqdVltbmxYsWKBwOFzRY48lfojz+Bgf+s1OfenXr+v6C5q1+sbzyjrWx77/e617vV3//IFzdNPcUxw645Hxw7WUiNNr/BCnH2KUyoszHo+rsbFxWIlI2V0zy5Yt05IlSwa9T2tra/HrvXv36uqrr9b8+fP13e9+d9DfM01Tpmn2uz0cDjt2cZ089ljihzjtGGuj+ThTWavsmFOZfF5eGx27z5cfrqVEnF7jhzj9EKM0vDjLeR7KTkQaGxvV2Ng4rPvu2bNHV199tebOnavvfe97CgSYiQDn9U7fHfleM0zfBYDqcGyw6t69e3XVVVdpxowZWr16tQ4dOlT8WVNTk1MPCxQXNBvJrJnevWZIRACgGhxLRNauXatt27Zp27Ztmj59ep+fVWl8LHyquNfMiNYRsafvUr0DgGpwrLX9yEc+IsuyBvwAnNSbiIxkHREqIgBQTbztg+eYhWrGaHbfJREBgOogEYHnFFdWHdHuu2x6BwDVRGsLzxnNXjM9ha4ZkyXeAaAqSETgOfb03XJnzaSzOWVz+TFMVEQAoDpobeE5I501U3p/xogAQHWQiMBz7GpGJmcpkx1+VaR0lo3J9F0AqApaW3hO6fiOnjK6Z+yKiBkKyDCMip8XAKA/EhF4Tmk1o5zumSTLuwNA1ZGIwHMCAUORUPkzZ3qXd+dlAQDVQosLT7KXaC9n5gwVEQCoPhIReNJIZs7YFREGqgJA9dDiwpNGst8My7sDQPWRiMCT7KpGciRjRFhVFQCqhkQEnlSsiJSx8V1x+i6DVQGgamhx4Um9+82U0TXDYFUAqDoSEXhScQfesioi9vRdEhEAqBYSEXiSvbrqiAarMmsGAKqGFhee1Ns1U87KqlREAKDaSETgSSOZvpssTt/lZQEA1UKLC08yR7TEu73pHRURAKgWEhF40sim77LXDABUGy0uPMlOJpJM3wWAMY1EBJ5kr45a3vRde0EzEhEAqBYSEXjSyPaasZd452UBANVCiwtPGsn0XTa9A4DqIxGBJ/UuaMY6IgAwlpGIwJPMkew1wzoiAFB1tLjwpJFM36UiAgDVRyICTypuejeCiojJYFUAqBpaXHiSPfOlvAXNGKwKANVGIgJPGllFxJ6+SyICANVCIgJPMsucvmtZVsnKqrwsAKBaaHHhSdEyp++msjlZVv5rVlYFgOohEYEn9c6aGV7XTOk0XyoiAFA9tLjwJDuZyOYsZbJDJyP2njSGIUWCvCwAoFpoceFJpTNfhlMVSZYMVDUMw7HzAgD0RSICTypdC2Q440RYVRUA3EGrC08yDEOR0PBnzthjREym7gJAVZGIwLOKi5oNYy0Rpu4CgDtodeFZxZkzZXXNUBEBgGoiEYFnFVdXHcZg1WLXDIkIAFQViQg8y+5mSZZTEWHDOwCoKlpdeFbvomZ0zQDAWOVoIvL+979fM2bMUDQaVXNzsz784Q9r7969Tj4kUGSWMVjV7r5hsCoAVJejre7VV1+tH/7wh3rttdf0+OOP64033tCNN97o5EMCRQxWBYCxL+TkwT/96U8Xv545c6buuusufeADH1A6nVY4HHbyoYHimiDlVERMxogAQFU5moiUOnLkiH7wgx/osssuO2ESkkwmlUwmi9/H43FJUjqdVjqdruj52Mer9HHHGj/EeaIYzWB+qfZEMjVk/F09+Z9HgsaYfa78cC0l4vQaP8Tphxil8uIs57kwLMve/NwZf/d3f6cHHnhAiURCl156qX7+859r0qRJA9535cqVWrVqVb/b16xZo1gs5uRpwoN+sC2g5w8F9Kczsnr3KYP/mf90Z0BP7Qvomuacrm8d3o69AICBJRIJLV26VB0dHaqvrx/0vmUnIidKFkpt2LBB8+bNkyS1t7fryJEjevPNN7Vq1So1NDTo5z//+YAbiw1UEWlpaVF7e/uQgZQrnU6rra1NCxYs8HQ3kR/iPFGMd/+fP2rN82/pr66erb++5rRBj7Hy/7yiHzy/W5+6arbuvHbw+7rFD9dSIk6v8UOcfohRKi/OeDyuxsbGYSUiZXfNLFu2TEuWLBn0Pq2trcWvGxsb1djYqDPOOENnnXWWWlpatH79es2fP7/f75mmKdM0+90eDocdu7hOHnss8UOcx8cYi+S/TuU0ZOypbD4fj5lj/3nyw7WUiNNr/BCnH2KUhhdnOc9D2YmInViMhF18Ka16AE4xiwuaDWevGXv6LrNmAKCaHBus+vzzz+v555/X5ZdfrgkTJmj79u36whe+oFNPPXXAaghQadHQSKbvMmsGAKrJsVa3pqZGP/7xj3Xttddqzpw5+uhHP6pzzz1X69atG7D7Bai0cvaaKS5oFqIiAgDV5FhF5LzzztOTTz7p1OGBIdnVDRY0A4Cxizo0PMssY2VVe2M8FjQDgOqi1YVn9S7xPozBqmkGqwKAG0hE4FnFTe+Gs/tuhsGqAOAGWl14VnkVEcaIAIAbSETgWdFCRSQ5nIpIsWuGlwQAVBOtLjyrOH23jIqIyfRdAKgqEhF4VnSYs2Ysy+pdR4SuGQCoKhIReNZw1xEpXfCMrhkAqC5aXXiW3c3SM8TKqqVdN1REAKC6SETgWXZ1I5uzlM6eOBmxp+4GDCkUMKpybgCAPBIReFZpdWOw7pnSqbuGQSICANVEIgLPKl2ufbCN71hVFQDcQyICzzIMo3d11eFURNhnBgCqjpYXnjac1VVZVRUA3EMiAk8bVkWk0G1jkogAQNWRiMDTiqurDrLMezLNhncA4BZaXnha76Jmg03fLQxWZXl3AKg6EhF42nAqIsV9ZqiIAEDV0fLC0+wqx2AVkWLXDBURAKg6EhF4mjmM/WZ61xHh5QAA1UbLC08zh1ERYfouALiHRASeNpwdeO29ZkhEAKD6SETgacUFzQYdrGqvI8LLAQCqjZYXnmZXRJLD6ZphsCoAVB2JCDytOGtmsAXNMmx6BwBuIRGBpxXXERnWYFVeDgBQbbS88LTh7b5bGCNC1wwAVB2JCDytd/fdwbpmqIgAgFtoeeFpw9prhnVEAMA1JCLwNHNYe82wsioAuIWWF57W2zXD9F0AGItIROBpUXuw6mAVkYy9+y6JCABUG4kIPG14FRG6ZgDALbS88DR7+m5ysFkzDFYFANeQiMDThjN9t4eVVQHANSQi8LTiyqqZgbtmcjlLqYy9oBkvBwCoNlpeeFrvOiIDV0RKExQqIgBQfSQi8LRi18wJKiKlCUqUiggAVB0tLzzNXhskm7OUzvZPRuypu6GAoVCQlwMAVBstLzzNLJmSO1D3TO/UXbplAMANJCLwtNIBqAOtJdK7zwwvBQBwA60vPM0wjN61RAZYXdVOREyWdwcAV5CIwPMGW101mWFVVQBwU1Va32QyqQsvvFCGYWjTpk3VeEigaLApvD2sqgoArqpKIvLZz35W06ZNq8ZDAf30Lmp24sGqLGYGAO5wvPX95S9/qbVr12r16tVOPxQwIDvJGLhrhooIALgp5OTBDxw4oNtuu00//elPFYvFhrx/MplUMpksfh+PxyVJ6XRa6XS6oudmH6/Sxx1r/BDnUDHaicixnlS/+3T1pCRJkaAx5p8jP1xLiTi9xg9x+iFGqbw4y3kuDMuyrBGf1SAsy9LixYv1J3/yJ/qHf/gH7dy5U7NmzdLGjRt14YUXDvg7K1eu1KpVq/rdvmbNmmElMsBAvrElqDc6Df3FGVldOKnvn/sz+ww9vjOoCyfm9BdzBl59FQBQnkQioaVLl6qjo0P19fWD3rfsisiJkoVSGzZs0HPPPad4PK4VK1YM+9grVqzQ8uXLi9/H43G1tLRo4cKFQwZSrnQ6rba2Ni1YsEDhcLiixx5L/BDnUDH+6NCLeqPzsM4+7wItvrDvWKU9v9kh7dyq1pZTtHjxedU65RHxw7WUiNNr/BCnH2KUyovT7tEYjrITkWXLlmnJkiWD3qe1tVX33HOP1q9fL9M0+/xs3rx5+tCHPqRHHnmk3++Zptnv/pIUDocdu7hOHnss8UOcJ4qxJpL/M0/njH4/T2eN/H3Mk+f58cO1lIjTa/wQpx9ilIYXZznPQ9mJSGNjoxobG4e83ze+8Q3dc889xe/37t2r97znPXrsscd0ySWXlPuwwIj1riPSf9ZM72BVZs0AgBscG6w6Y8aMPt+PGzdOknTqqadq+vTpTj0s0E9x1swg03eZNQMA7uBtIDyvd0GzE+++yzoiAOAOR6fvlmptbZVDE3SAQUUL+8gkWVkVAMYc3gbC83pXVh1gQTO7a4aKCAC4gtYXnsdeMwAwdpGIwPMGmzXTwxLvAOAqEhF43mB7zfTOmuGlAABuoPWF55l2RWTA6bvZPvcBAFQXiQg8b/AFzezBqiQiAOAGEhF4nj0jZqBZM72DVXkpAIAbaH3heb0VkROPETGpiACAK0hE4HnFdUQG6pqhIgIArqL1hecNuo4I03cBwFUkIvA8u9ul57gxItmcpXQ2v+0AiQgAuINEBJ53oopI6fd0zQCAO2h94Xkn2mumTyLCYFUAcAWJCDzPTjLyXTG9yYjdVRMJBhQIGK6cGwD4HYkIPM8s6XYprYIki6uq8jIAALfQAsPz7L1mpL5rifTuM0O3DAC4hUQEnmcYRsnGd70VEXvqbmmiAgCoLlpg+ELvgNWSRCTNGiIA4DYSEfhC7xTe3q6ZZLFrhpcBALiFFhi+MGhFhKm7AOAaEhH4gp1s9BmsyvLuAOA6EhH4wkCrq/bQNQMArqMFhi+YA1VEiuuIUBEBALeQiMAXzAEqIvaS74wRAQD3kIjAFwbab6Z3+i4vAwBwCy0wfMFORAYaI2JSEQEA15CIwBei9sqqAy5oxssAANxCCwxf6K2IlCxoxvRdAHAdiQh8wd5PJsn0XQAYU2iB4QsDjxGhIgIAbiMRgS/YVY8BZ80wWBUAXEMiAl8YqCJiJyUmXTMA4BpaYPiCOcBgVbpmAMB9JCLwhYGn79rriPAyAAC30ALDF8yBBqsyfRcAXEciAl8oVkRK1xEpTt8lEQEAt5CIwBfYawYAxiZaYPhCMREZaB0Rpu8CgGtIROALdtWj7xgRumYAwG0kIvCF4joiheQjnc0pm7MKP+NlAABuoQWGL5ihvhWR0rEiVEQAwD0kIvCF0pVVLcvq00XDOiIA4B5aYPiCPSA1Z0npbG8iEgkFZBiGm6cGAL7maCLS2toqwzD6fNx1111OPiQwoNL9ZJKZbHE9kSjVEABwVcjpB/jiF7+o2267rfj9uHHjnH5IoB8zFJBhSJaVX9SMfWYAYGxwPBGpq6tTU1OT0w8DDMowDJmhQDEJSbK8OwCMCY4nIl/60pf0j//4j2ppadFNN92kv/3bv1UkEhnwvslkUslksvh9PB6XJKXTaaXT6Yqel328Sh93rPFDnMONMRoKqied07HupI51pyRJZsg4aZ4bP1xLiTi9xg9x+iFGqbw4y3kuDMuyrBGf1RC+9rWv6eKLL9aECRP0/PPPa8WKFbr++uv10EMPDXj/lStXatWqVf1uX7NmjWKxmFOnCZ/4wgtBdaQN/c15GXWkDf2PV4NqqbX0N+dnh/5lAMCwJRIJLV26VB0dHaqvrx/0vmUnIidKFkpt2LBB8+bN63f7448/rhtvvFHt7e2aNGlSv58PVBFpaWlRe3v7kIGUK51Oq62tTQsWLFA4HK7osccSP8Q53Biv/dqz2nWkW49+7B062JnUXz/2kubNHK//9bF3VvFsR84P11IiTq/xQ5x+iFEqL854PK7GxsZhJSJld80sW7ZMS5YsGfQ+ra2tA95+6aWXSpK2bds2YCJimqZM0+x3ezgcduziOnnsscQPcQ4VY004/+eeVUAZKz9ltyYSOumeFz9cS4k4vcYPcfohRml4cZbzPJSdiDQ2NqqxsbHcX5Mkbdy4UZLU3Nw8ot8HRqN0v5ni9F0GqwKAqxwbrPq73/1O69ev19VXX62GhgZt2LBBn/70p/X+979fM2bMcOphgRMyi6ur9k7fZVVVAHCXY4mIaZp67LHHtGrVKiWTSc2cOVO33XabPvvZzzr1kMCgSpd572H6LgCMCY4lIhdffLHWr1/v1OGBshU3vitdWZWddwHAVbTC8I1oSddM0l5ZNURFBADcRCIC37D3lcnvNUPXDACMBSQi8I1on8GqdM0AwFhAKwzfsJOOJINVAWDMIBGBb5TOmkkWKiImiQgAuIpEBL5RnDWTzhUrIqwjAgDuohWGbxQrIgxWBYAxg0QEvmF3wyRLB6tSEQEAV9EKwzeifRY0oyICAGMBiQh8o89g1Qyb3gHAWEAiAt+IDrDpHeuIAIC7aIXhG72zZuiaAYCxgkQEvmEnHclMrrdrhr1mAMBVJCLwDbsbpm9FhJcAALiJVhi+YVdEjiUzyln520wqIgDgKhIR+IbdDdPZkyneZlIRAQBX0QrDN47vhjEMlngHALfRCsM3ju+GMUMBGYbh0tkAACQSEfjI8d0wTN0FAPeRiMA38hWQ3u+ZugsA7iMRgW8YhtFnTAhTdwHAfbTE8JXS7hi6ZgDAfSQi8JXS7hiTRAQAXEciAl8p7Y5h6i4AuI+WGL5SOoWXrhkAcB+JCHyltCISpSICAK6jJYavmAxWBYAxhUQEvtJ31gx//gDgNlpi+Eq0zzoiVEQAwG0kIvAV1hEBgLGFRAS+0mdlVQarAoDraInhK6VVEBY0AwD3kYjAV1jQDADGFlpi+ApjRABgbCERga+QiADA2EIiAl/pM1iVdUQAwHW0xPCVPiurhqiIAIDbSETgKyxoBgBjC4kIfIUl3gFgbKElhq8wWBUAxhYSEfgK64gAwNhCSwxfoSICAGMLiQh8pbQKYjJGBABc53hL/Itf/EKXXHKJampq1NjYqBtuuMHphwROiIoIAIwtIScP/vjjj+u2227TP//zP+uaa66RZVnavHmzkw8JDKp07RDWEQEA9zmWiGQyGd1xxx36yle+oltvvbV4+5w5c5x6SGBIDTVhBQOGYuGgwkHD7dMBAN9zLBH5/e9/rz179igQCOiiiy7S/v37deGFF2r16tU655xzBvydZDKpZDJZ/D4ej0uS0um00ul0Rc/PPl6ljzvW+CHOcmKMhaVv3nyB6qIhZTIZp0+tovxwLSXi9Bo/xOmHGKXy4iznuTAsy7JGfFaDePTRR/XBD35QM2bM0P3336/W1lZ99atf1dq1a/X6669r4sSJ/X5n5cqVWrVqVb/b16xZo1gs5sRpAgCACkskElq6dKk6OjpUX18/6H3LTkROlCyU2rBhg15//XV96EMf0ne+8x395V/+paR8xWP69Om655579PGPf7zf7w1UEWlpaVF7e/uQgZQrnU6rra1NCxYsUDgcruixxxI/xOmHGCXi9Bri9A4/xCiVF2c8HldjY+OwEpGyu2aWLVumJUuWDHqf1tZWdXZ2SpLOPvvs4u2maWr27NnatWvXgL9nmqZM0+x3ezgcduziOnnsscQPcfohRok4vYY4vcMPMUrDi7Oc56HsRKSxsVGNjY1D3m/u3LkyTVOvvfaaLr/8ckn5bGrnzp2aOXNmuQ8LAAA8yLHBqvX19br99tt19913q6WlRTNnztRXvvIVSdJNN93k1MMCAICTiKPriHzlK19RKBTShz/8YXV3d+uSSy7Rk08+qQkTJjj5sAAA4CThaCISDoe1evVqrV692smHAQAAJyk22wAAAK4hEQEAAK4hEQEAAK4hEQEAAK4hEQEAAK4hEQEAAK4hEQEAAK5xdB2R0bL344vH4xU/djqdViKRUDwe9/TeAH6I0w8xSsTpNcTpHX6IUSovTvv/9nD21R3TiYi9cV5LS4vLZwIAAMrV2dmphoaGQe9jWMNJV1ySy+W0d+9e1dXVyTCMih47Ho+rpaVFu3fvHnKL4pOZH+L0Q4wScXoNcXqHH2KUyovTsix1dnZq2rRpCgQGHwUypisigUBA06dPd/Qx6uvrPf2HY/NDnH6IUSJOryFO7/BDjNLw4xyqEmJjsCoAAHANiQgAAHCNbxMR0zR19913yzRNt0/FUX6I0w8xSsTpNcTpHX6IUXIuzjE9WBUAAHibbysiAADAfSQiAADANSQiAADANSQiAADANb5MRL71rW9p1qxZikajmjt3rp599lm3T6miVq5cKcMw+nw0NTW5fVqj9swzz+hP//RPNW3aNBmGoZ/+9Kd9fm5ZllauXKlp06appqZGV111lV5++WV3TnYUhorzIx/5SL/re+mll7pzsiN077336h3veIfq6uo0ZcoUfeADH9Brr73W5z5euJ7DidML1/PBBx/U+eefX1zoav78+frlL39Z/LkXrqU0dJxeuJbHu/fee2UYhu68887ibZW+nr5LRB577DHdeeed+tznPqeNGzfqiiuu0KJFi7Rr1y63T62izjnnHO3bt6/4sXnzZrdPadS6urp0wQUX6IEHHhjw51/+8pd1//3364EHHtCGDRvU1NSkBQsWFPcsOlkMFackXXfddX2u7xNPPFHFMxy9devW6VOf+pTWr1+vtrY2ZTIZLVy4UF1dXcX7eOF6DidO6eS/ntOnT9d9992nF154QS+88IKuueYaXX/99cV/Tl64ltLQcUon/7UstWHDBn33u9/V+eef3+f2il9Py2fe+c53Wrfffnuf284880zrrrvucumMKu/uu++2LrjgArdPw1GSrJ/85CfF73O5nNXU1GTdd999xdt6enqshoYG69vf/rYLZ1gZx8dpWZZ1yy23WNdff70r5+OUgwcPWpKsdevWWZbl3et5fJyW5c3raVmWNWHCBOuhhx7y7LW02XFalreuZWdnp3X66adbbW1t1pVXXmndcccdlmU589r0VUUklUrpxRdf1MKFC/vcvnDhQj333HMunZUztm7dqmnTpmnWrFlasmSJtm/f7vYpOWrHjh3av39/n2trmqauvPJKz11bSXr66ac1ZcoUnXHGGbrtttt08OBBt09pVDo6OiRJEydOlOTd63l8nDYvXc9sNqtHH31UXV1dmj9/vmev5fFx2rxyLT/1qU/pve99r9797nf3ud2J6zmmN72rtPb2dmWzWU2dOrXP7VOnTtX+/ftdOqvKu+SSS/Qf//EfOuOMM3TgwAHdc889uuyyy/Tyyy9r0qRJbp+eI+zrN9C1ffPNN904JccsWrRIN910k2bOnKkdO3bo85//vK655hq9+OKLJ+XKjpZlafny5br88st17rnnSvLm9RwoTsk713Pz5s2aP3++enp6NG7cOP3kJz/R2WefXfzn5JVreaI4Je9cy0cffVS///3vtWHDhn4/c+K16atExGYYRp/vLcvqd9vJbNGiRcWvzzvvPM2fP1+nnnqqHnnkES1fvtzFM3Oe16+tJN18883Fr88991zNmzdPM2fO1C9+8QvdcMMNLp7ZyCxbtkwvvfSSfvOb3/T7mZeu54ni9Mr1nDNnjjZt2qSjR4/q8ccf1y233KJ169YVf+6Va3miOM8++2xPXMvdu3frjjvu0Nq1axWNRk94v0peT191zTQ2NioYDParfhw8eLBfducltbW1Ou+887R161a3T8Ux9qwgv11bSWpubtbMmTNPyuv7V3/1V/rP//xPPfXUU5o+fXrxdq9dzxPFOZCT9XpGIhGddtppmjdvnu69915dcMEF+pd/+RfPXcsTxTmQk/Favvjiizp48KDmzp2rUCikUCikdevW6Rvf+IZCoVDxmlXyevoqEYlEIpo7d67a2tr63N7W1qbLLrvMpbNyXjKZ1CuvvKLm5ma3T8Uxs2bNUlNTU59rm0qltG7dOk9fW0k6fPiwdu/efVJdX8uytGzZMv34xz/Wk08+qVmzZvX5uVeu51BxDuRkvJ4DsSxLyWTSM9fyROw4B3IyXstrr71Wmzdv1qZNm4of8+bN04c+9CFt2rRJs2fPrvz1HPGQ2pPUo48+aoXDYevf/u3frD/+8Y/WnXfeadXW1lo7d+50+9Qq5jOf+Yz19NNPW9u3b7fWr19vve9977Pq6upO+hg7OzutjRs3Whs3brQkWffff7+1ceNG680337Qsy7Luu+8+q6Ghwfrxj39sbd682frgBz9oNTc3W/F43OUzL89gcXZ2dlqf+cxnrOeee87asWOH9dRTT1nz58+3TjnllJMqzk984hNWQ0OD9fTTT1v79u0rfiQSieJ9vHA9h4rTK9dzxYoV1jPPPGPt2LHDeumll6y///u/twKBgLV27VrLsrxxLS1r8Di9ci0HUjprxrIqfz19l4hYlmX967/+qzVz5kwrEolYF198cZ+pdF5w8803W83NzVY4HLamTZtm3XDDDdbLL7/s9mmN2lNPPWVJ6vdxyy23WJaVn1Z29913W01NTZZpmta73vUua/Pmze6e9AgMFmcikbAWLlxoTZ482QqHw9aMGTOsW265xdq1a5fbp12WgeKTZH3ve98r3scL13OoOL1yPT/60Y8W29TJkydb1157bTEJsSxvXEvLGjxOr1zLgRyfiFT6ehqWZVkjq6UAAACMjq/GiAAAgLGFRAQAALiGRAQAALiGRAQAALiGRAQAALiGRAQAALiGRAQAALiGRAQAALiGRAQAALiGRAQAALiGRAQAALiGRAQAALjm/wO6oebUe8nR+wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv_res = pd.DataFrame(opt0.cv_results_)\n",
    "cv_res\n",
    "cv_res.iloc[:, :].reset_index().loc[:, \"mean_test_score\"].plot()\n",
    "plt.grid()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_feature_selection__split_param</th>\n",
       "      <th>param_regression</th>\n",
       "      <th>param_regression__alpha</th>\n",
       "      <th>param_regression__l1_ratio</th>\n",
       "      <th>param_regression__max_depth</th>\n",
       "      <th>param_regression__min_samples_split</th>\n",
       "      <th>param_regression__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.955612</td>\n",
       "      <td>0.274197</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>2.743571</td>\n",
       "      <td>ElasticNet(alpha=0.9435871670614078, l1_ratio=...</td>\n",
       "      <td>0.387402</td>\n",
       "      <td>0.128819</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'feature_selection__split_param': 2.743571433...</td>\n",
       "      <td>0.297390</td>\n",
       "      <td>0.100177</td>\n",
       "      <td>0.251089</td>\n",
       "      <td>0.185337</td>\n",
       "      <td>0.206686</td>\n",
       "      <td>0.208136</td>\n",
       "      <td>0.066315</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.664954</td>\n",
       "      <td>0.175967</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>3.284402</td>\n",
       "      <td>ElasticNet(alpha=0.9435871670614078, l1_ratio=...</td>\n",
       "      <td>0.985515</td>\n",
       "      <td>0.703889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'feature_selection__split_param': 3.284402090...</td>\n",
       "      <td>0.263824</td>\n",
       "      <td>0.174915</td>\n",
       "      <td>0.290114</td>\n",
       "      <td>0.157732</td>\n",
       "      <td>0.220450</td>\n",
       "      <td>0.221407</td>\n",
       "      <td>0.050471</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.858914</td>\n",
       "      <td>0.095431</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>4.149169</td>\n",
       "      <td>ElasticNet(alpha=0.9435871670614078, l1_ratio=...</td>\n",
       "      <td>0.721623</td>\n",
       "      <td>0.930024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'feature_selection__split_param': 4.149169393...</td>\n",
       "      <td>0.243352</td>\n",
       "      <td>0.136737</td>\n",
       "      <td>0.291184</td>\n",
       "      <td>0.115503</td>\n",
       "      <td>0.225269</td>\n",
       "      <td>0.202409</td>\n",
       "      <td>0.066250</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.926795</td>\n",
       "      <td>0.157921</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>2.883225</td>\n",
       "      <td>ElasticNet(alpha=0.9435871670614078, l1_ratio=...</td>\n",
       "      <td>0.324929</td>\n",
       "      <td>0.066263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'feature_selection__split_param': 2.883225269...</td>\n",
       "      <td>0.292007</td>\n",
       "      <td>0.072773</td>\n",
       "      <td>0.262698</td>\n",
       "      <td>0.186038</td>\n",
       "      <td>0.198842</td>\n",
       "      <td>0.202471</td>\n",
       "      <td>0.075827</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.202653</td>\n",
       "      <td>0.156315</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>3.80773</td>\n",
       "      <td>ElasticNet(alpha=0.9435871670614078, l1_ratio=...</td>\n",
       "      <td>0.975746</td>\n",
       "      <td>0.854681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'feature_selection__split_param': 3.807729785...</td>\n",
       "      <td>0.259746</td>\n",
       "      <td>0.159653</td>\n",
       "      <td>0.269631</td>\n",
       "      <td>0.121148</td>\n",
       "      <td>0.225095</td>\n",
       "      <td>0.207055</td>\n",
       "      <td>0.057697</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.478855</td>\n",
       "      <td>0.423979</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>2.24902</td>\n",
       "      <td>ElasticNet(alpha=0.9435871670614078, l1_ratio=...</td>\n",
       "      <td>0.504889</td>\n",
       "      <td>0.786739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'feature_selection__split_param': 2.249020143...</td>\n",
       "      <td>0.283490</td>\n",
       "      <td>0.013976</td>\n",
       "      <td>0.234134</td>\n",
       "      <td>0.209243</td>\n",
       "      <td>0.230556</td>\n",
       "      <td>0.194280</td>\n",
       "      <td>0.093377</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.108378</td>\n",
       "      <td>0.322873</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>4.406906</td>\n",
       "      <td>ElasticNet(alpha=0.9435871670614078, l1_ratio=...</td>\n",
       "      <td>0.261723</td>\n",
       "      <td>0.06709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'feature_selection__split_param': 4.406905681...</td>\n",
       "      <td>0.208117</td>\n",
       "      <td>0.108407</td>\n",
       "      <td>0.265366</td>\n",
       "      <td>0.063524</td>\n",
       "      <td>0.188170</td>\n",
       "      <td>0.166717</td>\n",
       "      <td>0.072048</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.331275</td>\n",
       "      <td>0.209564</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>4.592474</td>\n",
       "      <td>ElasticNet(alpha=0.9435871670614078, l1_ratio=...</td>\n",
       "      <td>0.556117</td>\n",
       "      <td>0.92798</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'feature_selection__split_param': 4.592474169...</td>\n",
       "      <td>0.206492</td>\n",
       "      <td>-0.058499</td>\n",
       "      <td>0.276356</td>\n",
       "      <td>0.102009</td>\n",
       "      <td>0.217870</td>\n",
       "      <td>0.148846</td>\n",
       "      <td>0.117925</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.519911</td>\n",
       "      <td>0.308696</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>3.186457</td>\n",
       "      <td>ElasticNet(alpha=0.9435871670614078, l1_ratio=...</td>\n",
       "      <td>0.237075</td>\n",
       "      <td>0.058609</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'feature_selection__split_param': 3.186456979...</td>\n",
       "      <td>0.291513</td>\n",
       "      <td>0.048667</td>\n",
       "      <td>0.297975</td>\n",
       "      <td>0.141788</td>\n",
       "      <td>0.192013</td>\n",
       "      <td>0.194391</td>\n",
       "      <td>0.093990</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.416307</td>\n",
       "      <td>0.257447</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>3.707944</td>\n",
       "      <td>ElasticNet(alpha=0.9435871670614078, l1_ratio=...</td>\n",
       "      <td>0.58116</td>\n",
       "      <td>0.544714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'feature_selection__split_param': 3.707943921...</td>\n",
       "      <td>0.272307</td>\n",
       "      <td>0.150191</td>\n",
       "      <td>0.289525</td>\n",
       "      <td>0.112533</td>\n",
       "      <td>0.190268</td>\n",
       "      <td>0.202965</td>\n",
       "      <td>0.068447</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.694245</td>\n",
       "      <td>0.082981</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ElasticNet(alpha=0.9435871670614078, l1_ratio=...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.015915</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'feature_selection__split_param': 1.0, 'regre...</td>\n",
       "      <td>0.307438</td>\n",
       "      <td>0.166120</td>\n",
       "      <td>0.266938</td>\n",
       "      <td>0.197593</td>\n",
       "      <td>0.219809</td>\n",
       "      <td>0.231579</td>\n",
       "      <td>0.050166</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.452963</td>\n",
       "      <td>0.334866</td>\n",
       "      <td>0.000875</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ElasticNet(alpha=0.9435871670614078, l1_ratio=...</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.923575</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'feature_selection__split_param': 1.0, 'regre...</td>\n",
       "      <td>-1.788376</td>\n",
       "      <td>-14.786366</td>\n",
       "      <td>-2.239297</td>\n",
       "      <td>-2.727139</td>\n",
       "      <td>-8.280376</td>\n",
       "      <td>-5.964311</td>\n",
       "      <td>4.999725</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6.200231</td>\n",
       "      <td>0.491591</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>2.295694</td>\n",
       "      <td>ElasticNet(alpha=0.9435871670614078, l1_ratio=...</td>\n",
       "      <td>0.649691</td>\n",
       "      <td>0.967969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'feature_selection__split_param': 2.295693836...</td>\n",
       "      <td>0.251167</td>\n",
       "      <td>0.051449</td>\n",
       "      <td>0.280639</td>\n",
       "      <td>0.194117</td>\n",
       "      <td>0.215616</td>\n",
       "      <td>0.198598</td>\n",
       "      <td>0.079318</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.359272</td>\n",
       "      <td>0.271933</td>\n",
       "      <td>0.000778</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ElasticNet(alpha=0.9435871670614078, l1_ratio=...</td>\n",
       "      <td>0.222619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'feature_selection__split_param': 1.0, 'regre...</td>\n",
       "      <td>0.118173</td>\n",
       "      <td>-0.239424</td>\n",
       "      <td>0.137664</td>\n",
       "      <td>0.114510</td>\n",
       "      <td>0.106409</td>\n",
       "      <td>0.047466</td>\n",
       "      <td>0.143812</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.836319</td>\n",
       "      <td>0.343420</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>3.614311</td>\n",
       "      <td>ElasticNet(alpha=0.9435871670614078, l1_ratio=...</td>\n",
       "      <td>0.533968</td>\n",
       "      <td>0.649217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'feature_selection__split_param': 3.614311131...</td>\n",
       "      <td>0.269026</td>\n",
       "      <td>0.131434</td>\n",
       "      <td>0.289669</td>\n",
       "      <td>0.140416</td>\n",
       "      <td>0.195380</td>\n",
       "      <td>0.205185</td>\n",
       "      <td>0.064720</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.889836</td>\n",
       "      <td>0.555785</td>\n",
       "      <td>0.000793</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ElasticNet(alpha=0.9435871670614078, l1_ratio=...</td>\n",
       "      <td>0.743924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'feature_selection__split_param': 1.0, 'regre...</td>\n",
       "      <td>0.290957</td>\n",
       "      <td>0.116713</td>\n",
       "      <td>0.253306</td>\n",
       "      <td>0.189302</td>\n",
       "      <td>0.205934</td>\n",
       "      <td>0.211242</td>\n",
       "      <td>0.059277</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6.646044</td>\n",
       "      <td>0.295771</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>5.0</td>\n",
       "      <td>ElasticNet(alpha=0.9435871670614078, l1_ratio=...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'feature_selection__split_param': 5.0, 'regre...</td>\n",
       "      <td>0.188587</td>\n",
       "      <td>0.095108</td>\n",
       "      <td>0.290229</td>\n",
       "      <td>0.115304</td>\n",
       "      <td>0.184571</td>\n",
       "      <td>0.174760</td>\n",
       "      <td>0.068556</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6.072123</td>\n",
       "      <td>0.233909</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ElasticNet(alpha=0.9435871670614078, l1_ratio=...</td>\n",
       "      <td>0.943587</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'feature_selection__split_param': 1.0, 'regre...</td>\n",
       "      <td>0.309664</td>\n",
       "      <td>0.244975</td>\n",
       "      <td>0.295564</td>\n",
       "      <td>0.193913</td>\n",
       "      <td>0.213438</td>\n",
       "      <td>0.251511</td>\n",
       "      <td>0.045016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6.844964</td>\n",
       "      <td>0.101907</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ElasticNet(alpha=0.9435871670614078, l1_ratio=...</td>\n",
       "      <td>0.843921</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'feature_selection__split_param': 1.0, 'regre...</td>\n",
       "      <td>0.314928</td>\n",
       "      <td>0.207944</td>\n",
       "      <td>0.298354</td>\n",
       "      <td>0.193683</td>\n",
       "      <td>0.209582</td>\n",
       "      <td>0.244898</td>\n",
       "      <td>0.050985</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6.219252</td>\n",
       "      <td>0.407250</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ElasticNet(alpha=0.9435871670614078, l1_ratio=...</td>\n",
       "      <td>0.901154</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'feature_selection__split_param': 1.0, 'regre...</td>\n",
       "      <td>0.311557</td>\n",
       "      <td>0.230300</td>\n",
       "      <td>0.297072</td>\n",
       "      <td>0.194203</td>\n",
       "      <td>0.212180</td>\n",
       "      <td>0.249062</td>\n",
       "      <td>0.046760</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7.686096</td>\n",
       "      <td>0.298763</td>\n",
       "      <td>0.043528</td>\n",
       "      <td>0.023371</td>\n",
       "      <td>3.402399</td>\n",
       "      <td>RandomForestRegressor(random_state=2023)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>882</td>\n",
       "      <td>{'feature_selection__split_param': 3.402399391...</td>\n",
       "      <td>0.195515</td>\n",
       "      <td>-0.000379</td>\n",
       "      <td>0.277636</td>\n",
       "      <td>0.200459</td>\n",
       "      <td>0.226476</td>\n",
       "      <td>0.179941</td>\n",
       "      <td>0.094751</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8.772430</td>\n",
       "      <td>0.249486</td>\n",
       "      <td>0.056080</td>\n",
       "      <td>0.010153</td>\n",
       "      <td>1.107308</td>\n",
       "      <td>RandomForestRegressor(random_state=2023)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49</td>\n",
       "      <td>18</td>\n",
       "      <td>1728</td>\n",
       "      <td>{'feature_selection__split_param': 1.107308336...</td>\n",
       "      <td>0.250957</td>\n",
       "      <td>-0.153896</td>\n",
       "      <td>0.309210</td>\n",
       "      <td>0.184257</td>\n",
       "      <td>0.244886</td>\n",
       "      <td>0.167083</td>\n",
       "      <td>0.165294</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7.085426</td>\n",
       "      <td>0.161648</td>\n",
       "      <td>0.041187</td>\n",
       "      <td>0.007435</td>\n",
       "      <td>4.14416</td>\n",
       "      <td>RandomForestRegressor(random_state=2023)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27</td>\n",
       "      <td>21</td>\n",
       "      <td>1055</td>\n",
       "      <td>{'feature_selection__split_param': 4.144159769...</td>\n",
       "      <td>0.187647</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.304642</td>\n",
       "      <td>0.193043</td>\n",
       "      <td>0.219719</td>\n",
       "      <td>0.181742</td>\n",
       "      <td>0.098410</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.714594</td>\n",
       "      <td>0.332739</td>\n",
       "      <td>0.005251</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>3.897614</td>\n",
       "      <td>RandomForestRegressor(random_state=2023)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>18</td>\n",
       "      <td>124</td>\n",
       "      <td>{'feature_selection__split_param': 3.897613899...</td>\n",
       "      <td>0.193994</td>\n",
       "      <td>0.011310</td>\n",
       "      <td>0.296125</td>\n",
       "      <td>0.189266</td>\n",
       "      <td>0.212536</td>\n",
       "      <td>0.180646</td>\n",
       "      <td>0.093037</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6.643694</td>\n",
       "      <td>0.410349</td>\n",
       "      <td>0.023229</td>\n",
       "      <td>0.002760</td>\n",
       "      <td>2.437141</td>\n",
       "      <td>RandomForestRegressor(random_state=2023)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48</td>\n",
       "      <td>6</td>\n",
       "      <td>516</td>\n",
       "      <td>{'feature_selection__split_param': 2.437141107...</td>\n",
       "      <td>0.240137</td>\n",
       "      <td>-0.191014</td>\n",
       "      <td>0.288227</td>\n",
       "      <td>0.198481</td>\n",
       "      <td>0.244197</td>\n",
       "      <td>0.156006</td>\n",
       "      <td>0.175821</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7.866887</td>\n",
       "      <td>0.090283</td>\n",
       "      <td>0.066638</td>\n",
       "      <td>0.007961</td>\n",
       "      <td>1.25406</td>\n",
       "      <td>RandomForestRegressor(random_state=2023)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>1593</td>\n",
       "      <td>{'feature_selection__split_param': 1.254060240...</td>\n",
       "      <td>0.215197</td>\n",
       "      <td>-0.097394</td>\n",
       "      <td>0.292179</td>\n",
       "      <td>0.190551</td>\n",
       "      <td>0.251458</td>\n",
       "      <td>0.170398</td>\n",
       "      <td>0.138222</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6.258891</td>\n",
       "      <td>0.175430</td>\n",
       "      <td>0.019162</td>\n",
       "      <td>0.002346</td>\n",
       "      <td>3.410863</td>\n",
       "      <td>RandomForestRegressor(random_state=2023)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>19</td>\n",
       "      <td>616</td>\n",
       "      <td>{'feature_selection__split_param': 3.410863317...</td>\n",
       "      <td>0.196559</td>\n",
       "      <td>-0.063054</td>\n",
       "      <td>0.275290</td>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.210423</td>\n",
       "      <td>0.163116</td>\n",
       "      <td>0.116789</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>8.084763</td>\n",
       "      <td>0.137682</td>\n",
       "      <td>0.067810</td>\n",
       "      <td>0.009706</td>\n",
       "      <td>4.926109</td>\n",
       "      <td>RandomForestRegressor(random_state=2023)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1709</td>\n",
       "      <td>{'feature_selection__split_param': 4.926109047...</td>\n",
       "      <td>0.168971</td>\n",
       "      <td>0.015634</td>\n",
       "      <td>0.301663</td>\n",
       "      <td>0.188118</td>\n",
       "      <td>0.223827</td>\n",
       "      <td>0.179643</td>\n",
       "      <td>0.093729</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>7.000856</td>\n",
       "      <td>0.394788</td>\n",
       "      <td>0.037847</td>\n",
       "      <td>0.013305</td>\n",
       "      <td>3.618368</td>\n",
       "      <td>RandomForestRegressor(random_state=2023)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>831</td>\n",
       "      <td>{'feature_selection__split_param': 3.618367705...</td>\n",
       "      <td>0.203728</td>\n",
       "      <td>-0.045543</td>\n",
       "      <td>0.278585</td>\n",
       "      <td>0.150976</td>\n",
       "      <td>0.187787</td>\n",
       "      <td>0.155107</td>\n",
       "      <td>0.108588</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>8.670170</td>\n",
       "      <td>0.404974</td>\n",
       "      <td>0.073338</td>\n",
       "      <td>0.014462</td>\n",
       "      <td>1.597341</td>\n",
       "      <td>RandomForestRegressor(random_state=2023)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>1906</td>\n",
       "      <td>{'feature_selection__split_param': 1.597341411...</td>\n",
       "      <td>0.232011</td>\n",
       "      <td>-0.199546</td>\n",
       "      <td>0.297973</td>\n",
       "      <td>0.203758</td>\n",
       "      <td>0.249820</td>\n",
       "      <td>0.156803</td>\n",
       "      <td>0.180791</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>6.134662</td>\n",
       "      <td>0.272195</td>\n",
       "      <td>0.059004</td>\n",
       "      <td>0.018102</td>\n",
       "      <td>5.0</td>\n",
       "      <td>RandomForestRegressor(random_state=2023)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48</td>\n",
       "      <td>25</td>\n",
       "      <td>1714</td>\n",
       "      <td>{'feature_selection__split_param': 5.0, 'regre...</td>\n",
       "      <td>0.166882</td>\n",
       "      <td>0.041483</td>\n",
       "      <td>0.299792</td>\n",
       "      <td>0.188002</td>\n",
       "      <td>0.226982</td>\n",
       "      <td>0.184628</td>\n",
       "      <td>0.084704</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4.735771</td>\n",
       "      <td>0.238337</td>\n",
       "      <td>0.007458</td>\n",
       "      <td>0.004747</td>\n",
       "      <td>5.0</td>\n",
       "      <td>RandomForestRegressor(random_state=2023)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>134</td>\n",
       "      <td>{'feature_selection__split_param': 5.0, 'regre...</td>\n",
       "      <td>0.122123</td>\n",
       "      <td>-0.002188</td>\n",
       "      <td>0.308441</td>\n",
       "      <td>0.145420</td>\n",
       "      <td>0.202791</td>\n",
       "      <td>0.155317</td>\n",
       "      <td>0.101694</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5.581917</td>\n",
       "      <td>0.348275</td>\n",
       "      <td>0.063457</td>\n",
       "      <td>0.012626</td>\n",
       "      <td>5.0</td>\n",
       "      <td>RandomForestRegressor(random_state=2023)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>1891</td>\n",
       "      <td>{'feature_selection__split_param': 5.0, 'regre...</td>\n",
       "      <td>0.166914</td>\n",
       "      <td>0.042002</td>\n",
       "      <td>0.300278</td>\n",
       "      <td>0.189399</td>\n",
       "      <td>0.227099</td>\n",
       "      <td>0.185138</td>\n",
       "      <td>0.084683</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4.416850</td>\n",
       "      <td>0.229190</td>\n",
       "      <td>0.007719</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>1.702168</td>\n",
       "      <td>RandomForestRegressor(random_state=2023)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43</td>\n",
       "      <td>22</td>\n",
       "      <td>252</td>\n",
       "      <td>{'feature_selection__split_param': 1.702167997...</td>\n",
       "      <td>0.215000</td>\n",
       "      <td>-0.206758</td>\n",
       "      <td>0.298938</td>\n",
       "      <td>0.205449</td>\n",
       "      <td>0.250341</td>\n",
       "      <td>0.152594</td>\n",
       "      <td>0.182643</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>4.363534</td>\n",
       "      <td>0.037931</td>\n",
       "      <td>0.016642</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>3.839467</td>\n",
       "      <td>RandomForestRegressor(random_state=2023)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "      <td>628</td>\n",
       "      <td>{'feature_selection__split_param': 3.839466547...</td>\n",
       "      <td>0.199206</td>\n",
       "      <td>0.043280</td>\n",
       "      <td>0.288629</td>\n",
       "      <td>0.199278</td>\n",
       "      <td>0.227028</td>\n",
       "      <td>0.191484</td>\n",
       "      <td>0.080976</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>7.303756</td>\n",
       "      <td>0.136521</td>\n",
       "      <td>0.064390</td>\n",
       "      <td>0.001296</td>\n",
       "      <td>1.0</td>\n",
       "      <td>RandomForestRegressor(random_state=2023)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "      <td>{'feature_selection__split_param': 1.0, 'regre...</td>\n",
       "      <td>0.268300</td>\n",
       "      <td>-0.172004</td>\n",
       "      <td>0.321713</td>\n",
       "      <td>0.182719</td>\n",
       "      <td>0.247289</td>\n",
       "      <td>0.169604</td>\n",
       "      <td>0.176511</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4.938611</td>\n",
       "      <td>0.118093</td>\n",
       "      <td>0.042937</td>\n",
       "      <td>0.001237</td>\n",
       "      <td>2.239479</td>\n",
       "      <td>RandomForestRegressor(random_state=2023)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "      <td>25</td>\n",
       "      <td>1676</td>\n",
       "      <td>{'feature_selection__split_param': 2.239478616...</td>\n",
       "      <td>0.220340</td>\n",
       "      <td>-0.063500</td>\n",
       "      <td>0.280547</td>\n",
       "      <td>0.199975</td>\n",
       "      <td>0.258148</td>\n",
       "      <td>0.179102</td>\n",
       "      <td>0.124524</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>5.165508</td>\n",
       "      <td>0.141476</td>\n",
       "      <td>0.051260</td>\n",
       "      <td>0.001668</td>\n",
       "      <td>2.717982</td>\n",
       "      <td>RandomForestRegressor(random_state=2023)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "      <td>25</td>\n",
       "      <td>2000</td>\n",
       "      <td>{'feature_selection__split_param': 2.717982230...</td>\n",
       "      <td>0.191624</td>\n",
       "      <td>-0.020683</td>\n",
       "      <td>0.279389</td>\n",
       "      <td>0.199238</td>\n",
       "      <td>0.251833</td>\n",
       "      <td>0.180280</td>\n",
       "      <td>0.105657</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>4.780634</td>\n",
       "      <td>0.109932</td>\n",
       "      <td>0.021238</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>1.005896</td>\n",
       "      <td>RandomForestRegressor(random_state=2023)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>746</td>\n",
       "      <td>{'feature_selection__split_param': 1.005896164...</td>\n",
       "      <td>0.268749</td>\n",
       "      <td>-0.172517</td>\n",
       "      <td>0.315958</td>\n",
       "      <td>0.184849</td>\n",
       "      <td>0.241209</td>\n",
       "      <td>0.167650</td>\n",
       "      <td>0.175292</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>4.901277</td>\n",
       "      <td>0.101657</td>\n",
       "      <td>0.047451</td>\n",
       "      <td>0.001944</td>\n",
       "      <td>4.990262</td>\n",
       "      <td>RandomForestRegressor(random_state=2023)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>1694</td>\n",
       "      <td>{'feature_selection__split_param': 4.990261644...</td>\n",
       "      <td>0.127549</td>\n",
       "      <td>-0.084746</td>\n",
       "      <td>0.307364</td>\n",
       "      <td>0.120794</td>\n",
       "      <td>0.190605</td>\n",
       "      <td>0.132313</td>\n",
       "      <td>0.127523</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        3.955612      0.274197         0.000460        0.000032   \n",
       "1        3.664954      0.175967         0.000466        0.000076   \n",
       "2        3.858914      0.095431         0.000407        0.000031   \n",
       "3        3.926795      0.157921         0.000441        0.000041   \n",
       "4        4.202653      0.156315         0.000439        0.000034   \n",
       "5        4.478855      0.423979         0.000522        0.000064   \n",
       "6        4.108378      0.322873         0.000479        0.000055   \n",
       "7        4.331275      0.209564         0.000429        0.000018   \n",
       "8        4.519911      0.308696         0.000450        0.000039   \n",
       "9        4.416307      0.257447         0.000452        0.000010   \n",
       "10       4.694245      0.082981         0.000666        0.000050   \n",
       "11       5.452963      0.334866         0.000875        0.000149   \n",
       "12       6.200231      0.491591         0.000600        0.000070   \n",
       "13       5.359272      0.271933         0.000778        0.000129   \n",
       "14       5.836319      0.343420         0.000460        0.000004   \n",
       "15       5.889836      0.555785         0.000793        0.000085   \n",
       "16       6.646044      0.295771         0.000468        0.000054   \n",
       "17       6.072123      0.233909         0.000791        0.000293   \n",
       "18       6.844964      0.101907         0.000726        0.000085   \n",
       "19       6.219252      0.407250         0.000759        0.000107   \n",
       "20       7.686096      0.298763         0.043528        0.023371   \n",
       "21       8.772430      0.249486         0.056080        0.010153   \n",
       "22       7.085426      0.161648         0.041187        0.007435   \n",
       "23       5.714594      0.332739         0.005251        0.000803   \n",
       "24       6.643694      0.410349         0.023229        0.002760   \n",
       "25       7.866887      0.090283         0.066638        0.007961   \n",
       "26       6.258891      0.175430         0.019162        0.002346   \n",
       "27       8.084763      0.137682         0.067810        0.009706   \n",
       "28       7.000856      0.394788         0.037847        0.013305   \n",
       "29       8.670170      0.404974         0.073338        0.014462   \n",
       "30       6.134662      0.272195         0.059004        0.018102   \n",
       "31       4.735771      0.238337         0.007458        0.004747   \n",
       "32       5.581917      0.348275         0.063457        0.012626   \n",
       "33       4.416850      0.229190         0.007719        0.000483   \n",
       "34       4.363534      0.037931         0.016642        0.000770   \n",
       "35       7.303756      0.136521         0.064390        0.001296   \n",
       "36       4.938611      0.118093         0.042937        0.001237   \n",
       "37       5.165508      0.141476         0.051260        0.001668   \n",
       "38       4.780634      0.109932         0.021238        0.000508   \n",
       "39       4.901277      0.101657         0.047451        0.001944   \n",
       "\n",
       "   param_feature_selection__split_param  \\\n",
       "0                              2.743571   \n",
       "1                              3.284402   \n",
       "2                              4.149169   \n",
       "3                              2.883225   \n",
       "4                               3.80773   \n",
       "5                               2.24902   \n",
       "6                              4.406906   \n",
       "7                              4.592474   \n",
       "8                              3.186457   \n",
       "9                              3.707944   \n",
       "10                                  1.0   \n",
       "11                                  1.0   \n",
       "12                             2.295694   \n",
       "13                                  1.0   \n",
       "14                             3.614311   \n",
       "15                                  1.0   \n",
       "16                                  5.0   \n",
       "17                                  1.0   \n",
       "18                                  1.0   \n",
       "19                                  1.0   \n",
       "20                             3.402399   \n",
       "21                             1.107308   \n",
       "22                              4.14416   \n",
       "23                             3.897614   \n",
       "24                             2.437141   \n",
       "25                              1.25406   \n",
       "26                             3.410863   \n",
       "27                             4.926109   \n",
       "28                             3.618368   \n",
       "29                             1.597341   \n",
       "30                                  5.0   \n",
       "31                                  5.0   \n",
       "32                                  5.0   \n",
       "33                             1.702168   \n",
       "34                             3.839467   \n",
       "35                                  1.0   \n",
       "36                             2.239479   \n",
       "37                             2.717982   \n",
       "38                             1.005896   \n",
       "39                             4.990262   \n",
       "\n",
       "                                     param_regression param_regression__alpha  \\\n",
       "0   ElasticNet(alpha=0.9435871670614078, l1_ratio=...                0.387402   \n",
       "1   ElasticNet(alpha=0.9435871670614078, l1_ratio=...                0.985515   \n",
       "2   ElasticNet(alpha=0.9435871670614078, l1_ratio=...                0.721623   \n",
       "3   ElasticNet(alpha=0.9435871670614078, l1_ratio=...                0.324929   \n",
       "4   ElasticNet(alpha=0.9435871670614078, l1_ratio=...                0.975746   \n",
       "5   ElasticNet(alpha=0.9435871670614078, l1_ratio=...                0.504889   \n",
       "6   ElasticNet(alpha=0.9435871670614078, l1_ratio=...                0.261723   \n",
       "7   ElasticNet(alpha=0.9435871670614078, l1_ratio=...                0.556117   \n",
       "8   ElasticNet(alpha=0.9435871670614078, l1_ratio=...                0.237075   \n",
       "9   ElasticNet(alpha=0.9435871670614078, l1_ratio=...                 0.58116   \n",
       "10  ElasticNet(alpha=0.9435871670614078, l1_ratio=...                     1.0   \n",
       "11  ElasticNet(alpha=0.9435871670614078, l1_ratio=...                  0.0001   \n",
       "12  ElasticNet(alpha=0.9435871670614078, l1_ratio=...                0.649691   \n",
       "13  ElasticNet(alpha=0.9435871670614078, l1_ratio=...                0.222619   \n",
       "14  ElasticNet(alpha=0.9435871670614078, l1_ratio=...                0.533968   \n",
       "15  ElasticNet(alpha=0.9435871670614078, l1_ratio=...                0.743924   \n",
       "16  ElasticNet(alpha=0.9435871670614078, l1_ratio=...                     1.0   \n",
       "17  ElasticNet(alpha=0.9435871670614078, l1_ratio=...                0.943587   \n",
       "18  ElasticNet(alpha=0.9435871670614078, l1_ratio=...                0.843921   \n",
       "19  ElasticNet(alpha=0.9435871670614078, l1_ratio=...                0.901154   \n",
       "20           RandomForestRegressor(random_state=2023)                     NaN   \n",
       "21           RandomForestRegressor(random_state=2023)                     NaN   \n",
       "22           RandomForestRegressor(random_state=2023)                     NaN   \n",
       "23           RandomForestRegressor(random_state=2023)                     NaN   \n",
       "24           RandomForestRegressor(random_state=2023)                     NaN   \n",
       "25           RandomForestRegressor(random_state=2023)                     NaN   \n",
       "26           RandomForestRegressor(random_state=2023)                     NaN   \n",
       "27           RandomForestRegressor(random_state=2023)                     NaN   \n",
       "28           RandomForestRegressor(random_state=2023)                     NaN   \n",
       "29           RandomForestRegressor(random_state=2023)                     NaN   \n",
       "30           RandomForestRegressor(random_state=2023)                     NaN   \n",
       "31           RandomForestRegressor(random_state=2023)                     NaN   \n",
       "32           RandomForestRegressor(random_state=2023)                     NaN   \n",
       "33           RandomForestRegressor(random_state=2023)                     NaN   \n",
       "34           RandomForestRegressor(random_state=2023)                     NaN   \n",
       "35           RandomForestRegressor(random_state=2023)                     NaN   \n",
       "36           RandomForestRegressor(random_state=2023)                     NaN   \n",
       "37           RandomForestRegressor(random_state=2023)                     NaN   \n",
       "38           RandomForestRegressor(random_state=2023)                     NaN   \n",
       "39           RandomForestRegressor(random_state=2023)                     NaN   \n",
       "\n",
       "   param_regression__l1_ratio param_regression__max_depth  \\\n",
       "0                    0.128819                         NaN   \n",
       "1                    0.703889                         NaN   \n",
       "2                    0.930024                         NaN   \n",
       "3                    0.066263                         NaN   \n",
       "4                    0.854681                         NaN   \n",
       "5                    0.786739                         NaN   \n",
       "6                     0.06709                         NaN   \n",
       "7                     0.92798                         NaN   \n",
       "8                    0.058609                         NaN   \n",
       "9                    0.544714                         NaN   \n",
       "10                   0.015915                         NaN   \n",
       "11                   0.923575                         NaN   \n",
       "12                   0.967969                         NaN   \n",
       "13                        0.0                         NaN   \n",
       "14                   0.649217                         NaN   \n",
       "15                        0.0                         NaN   \n",
       "16                        0.0                         NaN   \n",
       "17                        1.0                         NaN   \n",
       "18                        1.0                         NaN   \n",
       "19                        1.0                         NaN   \n",
       "20                        NaN                          11   \n",
       "21                        NaN                          49   \n",
       "22                        NaN                          27   \n",
       "23                        NaN                          30   \n",
       "24                        NaN                          48   \n",
       "25                        NaN                           4   \n",
       "26                        NaN                          29   \n",
       "27                        NaN                           2   \n",
       "28                        NaN                          10   \n",
       "29                        NaN                          20   \n",
       "30                        NaN                          48   \n",
       "31                        NaN                          15   \n",
       "32                        NaN                          50   \n",
       "33                        NaN                          43   \n",
       "34                        NaN                          21   \n",
       "35                        NaN                           8   \n",
       "36                        NaN                          31   \n",
       "37                        NaN                          28   \n",
       "38                        NaN                          40   \n",
       "39                        NaN                          43   \n",
       "\n",
       "   param_regression__min_samples_split param_regression__n_estimators  \\\n",
       "0                                  NaN                            NaN   \n",
       "1                                  NaN                            NaN   \n",
       "2                                  NaN                            NaN   \n",
       "3                                  NaN                            NaN   \n",
       "4                                  NaN                            NaN   \n",
       "5                                  NaN                            NaN   \n",
       "6                                  NaN                            NaN   \n",
       "7                                  NaN                            NaN   \n",
       "8                                  NaN                            NaN   \n",
       "9                                  NaN                            NaN   \n",
       "10                                 NaN                            NaN   \n",
       "11                                 NaN                            NaN   \n",
       "12                                 NaN                            NaN   \n",
       "13                                 NaN                            NaN   \n",
       "14                                 NaN                            NaN   \n",
       "15                                 NaN                            NaN   \n",
       "16                                 NaN                            NaN   \n",
       "17                                 NaN                            NaN   \n",
       "18                                 NaN                            NaN   \n",
       "19                                 NaN                            NaN   \n",
       "20                                  24                            882   \n",
       "21                                  18                           1728   \n",
       "22                                  21                           1055   \n",
       "23                                  18                            124   \n",
       "24                                   6                            516   \n",
       "25                                  24                           1593   \n",
       "26                                  19                            616   \n",
       "27                                  23                           1709   \n",
       "28                                   3                            831   \n",
       "29                                  19                           1906   \n",
       "30                                  25                           1714   \n",
       "31                                  15                            134   \n",
       "32                                  25                           1891   \n",
       "33                                  22                            252   \n",
       "34                                  25                            628   \n",
       "35                                   2                           2000   \n",
       "36                                  25                           1676   \n",
       "37                                  25                           2000   \n",
       "38                                  11                            746   \n",
       "39                                  10                           1694   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'feature_selection__split_param': 2.743571433...           0.297390   \n",
       "1   {'feature_selection__split_param': 3.284402090...           0.263824   \n",
       "2   {'feature_selection__split_param': 4.149169393...           0.243352   \n",
       "3   {'feature_selection__split_param': 2.883225269...           0.292007   \n",
       "4   {'feature_selection__split_param': 3.807729785...           0.259746   \n",
       "5   {'feature_selection__split_param': 2.249020143...           0.283490   \n",
       "6   {'feature_selection__split_param': 4.406905681...           0.208117   \n",
       "7   {'feature_selection__split_param': 4.592474169...           0.206492   \n",
       "8   {'feature_selection__split_param': 3.186456979...           0.291513   \n",
       "9   {'feature_selection__split_param': 3.707943921...           0.272307   \n",
       "10  {'feature_selection__split_param': 1.0, 'regre...           0.307438   \n",
       "11  {'feature_selection__split_param': 1.0, 'regre...          -1.788376   \n",
       "12  {'feature_selection__split_param': 2.295693836...           0.251167   \n",
       "13  {'feature_selection__split_param': 1.0, 'regre...           0.118173   \n",
       "14  {'feature_selection__split_param': 3.614311131...           0.269026   \n",
       "15  {'feature_selection__split_param': 1.0, 'regre...           0.290957   \n",
       "16  {'feature_selection__split_param': 5.0, 'regre...           0.188587   \n",
       "17  {'feature_selection__split_param': 1.0, 'regre...           0.309664   \n",
       "18  {'feature_selection__split_param': 1.0, 'regre...           0.314928   \n",
       "19  {'feature_selection__split_param': 1.0, 'regre...           0.311557   \n",
       "20  {'feature_selection__split_param': 3.402399391...           0.195515   \n",
       "21  {'feature_selection__split_param': 1.107308336...           0.250957   \n",
       "22  {'feature_selection__split_param': 4.144159769...           0.187647   \n",
       "23  {'feature_selection__split_param': 3.897613899...           0.193994   \n",
       "24  {'feature_selection__split_param': 2.437141107...           0.240137   \n",
       "25  {'feature_selection__split_param': 1.254060240...           0.215197   \n",
       "26  {'feature_selection__split_param': 3.410863317...           0.196559   \n",
       "27  {'feature_selection__split_param': 4.926109047...           0.168971   \n",
       "28  {'feature_selection__split_param': 3.618367705...           0.203728   \n",
       "29  {'feature_selection__split_param': 1.597341411...           0.232011   \n",
       "30  {'feature_selection__split_param': 5.0, 'regre...           0.166882   \n",
       "31  {'feature_selection__split_param': 5.0, 'regre...           0.122123   \n",
       "32  {'feature_selection__split_param': 5.0, 'regre...           0.166914   \n",
       "33  {'feature_selection__split_param': 1.702167997...           0.215000   \n",
       "34  {'feature_selection__split_param': 3.839466547...           0.199206   \n",
       "35  {'feature_selection__split_param': 1.0, 'regre...           0.268300   \n",
       "36  {'feature_selection__split_param': 2.239478616...           0.220340   \n",
       "37  {'feature_selection__split_param': 2.717982230...           0.191624   \n",
       "38  {'feature_selection__split_param': 1.005896164...           0.268749   \n",
       "39  {'feature_selection__split_param': 4.990261644...           0.127549   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.100177           0.251089           0.185337   \n",
       "1            0.174915           0.290114           0.157732   \n",
       "2            0.136737           0.291184           0.115503   \n",
       "3            0.072773           0.262698           0.186038   \n",
       "4            0.159653           0.269631           0.121148   \n",
       "5            0.013976           0.234134           0.209243   \n",
       "6            0.108407           0.265366           0.063524   \n",
       "7           -0.058499           0.276356           0.102009   \n",
       "8            0.048667           0.297975           0.141788   \n",
       "9            0.150191           0.289525           0.112533   \n",
       "10           0.166120           0.266938           0.197593   \n",
       "11         -14.786366          -2.239297          -2.727139   \n",
       "12           0.051449           0.280639           0.194117   \n",
       "13          -0.239424           0.137664           0.114510   \n",
       "14           0.131434           0.289669           0.140416   \n",
       "15           0.116713           0.253306           0.189302   \n",
       "16           0.095108           0.290229           0.115304   \n",
       "17           0.244975           0.295564           0.193913   \n",
       "18           0.207944           0.298354           0.193683   \n",
       "19           0.230300           0.297072           0.194203   \n",
       "20          -0.000379           0.277636           0.200459   \n",
       "21          -0.153896           0.309210           0.184257   \n",
       "22           0.003659           0.304642           0.193043   \n",
       "23           0.011310           0.296125           0.189266   \n",
       "24          -0.191014           0.288227           0.198481   \n",
       "25          -0.097394           0.292179           0.190551   \n",
       "26          -0.063054           0.275290           0.196364   \n",
       "27           0.015634           0.301663           0.188118   \n",
       "28          -0.045543           0.278585           0.150976   \n",
       "29          -0.199546           0.297973           0.203758   \n",
       "30           0.041483           0.299792           0.188002   \n",
       "31          -0.002188           0.308441           0.145420   \n",
       "32           0.042002           0.300278           0.189399   \n",
       "33          -0.206758           0.298938           0.205449   \n",
       "34           0.043280           0.288629           0.199278   \n",
       "35          -0.172004           0.321713           0.182719   \n",
       "36          -0.063500           0.280547           0.199975   \n",
       "37          -0.020683           0.279389           0.199238   \n",
       "38          -0.172517           0.315958           0.184849   \n",
       "39          -0.084746           0.307364           0.120794   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.206686         0.208136        0.066315                7  \n",
       "1            0.220450         0.221407        0.050471                5  \n",
       "2            0.225269         0.202409        0.066250               12  \n",
       "3            0.198842         0.202471        0.075827               11  \n",
       "4            0.225095         0.207055        0.057697                8  \n",
       "5            0.230556         0.194280        0.093377               15  \n",
       "6            0.188170         0.166717        0.072048               30  \n",
       "7            0.217870         0.148846        0.117925               37  \n",
       "8            0.192013         0.194391        0.093990               14  \n",
       "9            0.190268         0.202965        0.068447               10  \n",
       "10           0.219809         0.231579        0.050166                4  \n",
       "11          -8.280376        -5.964311        4.999725               40  \n",
       "12           0.215616         0.198598        0.079318               13  \n",
       "13           0.106409         0.047466        0.143812               39  \n",
       "14           0.195380         0.205185        0.064720                9  \n",
       "15           0.205934         0.211242        0.059277                6  \n",
       "16           0.184571         0.174760        0.068556               25  \n",
       "17           0.213438         0.251511        0.045016                1  \n",
       "18           0.209582         0.244898        0.050985                3  \n",
       "19           0.212180         0.249062        0.046760                2  \n",
       "20           0.226476         0.179941        0.094751               22  \n",
       "21           0.244886         0.167083        0.165294               29  \n",
       "22           0.219719         0.181742        0.098410               19  \n",
       "23           0.212536         0.180646        0.093037               20  \n",
       "24           0.244197         0.156006        0.175821               33  \n",
       "25           0.251458         0.170398        0.138222               26  \n",
       "26           0.210423         0.163116        0.116789               31  \n",
       "27           0.223827         0.179643        0.093729               23  \n",
       "28           0.187787         0.155107        0.108588               35  \n",
       "29           0.249820         0.156803        0.180791               32  \n",
       "30           0.226982         0.184628        0.084704               18  \n",
       "31           0.202791         0.155317        0.101694               34  \n",
       "32           0.227099         0.185138        0.084683               17  \n",
       "33           0.250341         0.152594        0.182643               36  \n",
       "34           0.227028         0.191484        0.080976               16  \n",
       "35           0.247289         0.169604        0.176511               27  \n",
       "36           0.258148         0.179102        0.124524               24  \n",
       "37           0.251833         0.180280        0.105657               21  \n",
       "38           0.241209         0.167650        0.175292               28  \n",
       "39           0.190605         0.132313        0.127523               38  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_selection__split_param</th>\n",
       "      <th>regression</th>\n",
       "      <th>regression__alpha</th>\n",
       "      <th>regression__l1_ratio</th>\n",
       "      <th>regression__max_depth</th>\n",
       "      <th>regression__min_samples_split</th>\n",
       "      <th>regression__n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>ElasticNet(alpha=0.9435871670614078, l1_ratio=...</td>\n",
       "      <td>0.943587</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>ElasticNet(alpha=0.9435871670614078, l1_ratio=...</td>\n",
       "      <td>0.901154</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>ElasticNet(alpha=0.9435871670614078, l1_ratio=...</td>\n",
       "      <td>0.843921</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>ElasticNet(alpha=0.9435871670614078, l1_ratio=...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015915</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.284402</td>\n",
       "      <td>ElasticNet(alpha=0.9435871670614078, l1_ratio=...</td>\n",
       "      <td>0.985515</td>\n",
       "      <td>0.703889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>ElasticNet(alpha=0.9435871670614078, l1_ratio=...</td>\n",
       "      <td>0.743924</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.743571</td>\n",
       "      <td>ElasticNet(alpha=0.9435871670614078, l1_ratio=...</td>\n",
       "      <td>0.387402</td>\n",
       "      <td>0.128819</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.807730</td>\n",
       "      <td>ElasticNet(alpha=0.9435871670614078, l1_ratio=...</td>\n",
       "      <td>0.975746</td>\n",
       "      <td>0.854681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.614311</td>\n",
       "      <td>ElasticNet(alpha=0.9435871670614078, l1_ratio=...</td>\n",
       "      <td>0.533968</td>\n",
       "      <td>0.649217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.707944</td>\n",
       "      <td>ElasticNet(alpha=0.9435871670614078, l1_ratio=...</td>\n",
       "      <td>0.581160</td>\n",
       "      <td>0.544714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.883225</td>\n",
       "      <td>ElasticNet(alpha=0.9435871670614078, l1_ratio=...</td>\n",
       "      <td>0.324929</td>\n",
       "      <td>0.066263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.149169</td>\n",
       "      <td>ElasticNet(alpha=0.9435871670614078, l1_ratio=...</td>\n",
       "      <td>0.721623</td>\n",
       "      <td>0.930024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.295694</td>\n",
       "      <td>ElasticNet(alpha=0.9435871670614078, l1_ratio=...</td>\n",
       "      <td>0.649691</td>\n",
       "      <td>0.967969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.186457</td>\n",
       "      <td>ElasticNet(alpha=0.9435871670614078, l1_ratio=...</td>\n",
       "      <td>0.237075</td>\n",
       "      <td>0.058609</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.249020</td>\n",
       "      <td>ElasticNet(alpha=0.9435871670614078, l1_ratio=...</td>\n",
       "      <td>0.504889</td>\n",
       "      <td>0.786739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.839467</td>\n",
       "      <td>RandomForestRegressor(random_state=2023)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>628.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>RandomForestRegressor(random_state=2023)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1891.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>RandomForestRegressor(random_state=2023)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1714.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4.144160</td>\n",
       "      <td>RandomForestRegressor(random_state=2023)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1055.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3.897614</td>\n",
       "      <td>RandomForestRegressor(random_state=2023)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.717982</td>\n",
       "      <td>RandomForestRegressor(random_state=2023)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3.402399</td>\n",
       "      <td>RandomForestRegressor(random_state=2023)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>882.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.926109</td>\n",
       "      <td>RandomForestRegressor(random_state=2023)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1709.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.239479</td>\n",
       "      <td>RandomForestRegressor(random_state=2023)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1676.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>ElasticNet(alpha=0.9435871670614078, l1_ratio=...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.254060</td>\n",
       "      <td>RandomForestRegressor(random_state=2023)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1593.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>RandomForestRegressor(random_state=2023)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.005896</td>\n",
       "      <td>RandomForestRegressor(random_state=2023)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>746.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.107308</td>\n",
       "      <td>RandomForestRegressor(random_state=2023)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1728.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.406906</td>\n",
       "      <td>ElasticNet(alpha=0.9435871670614078, l1_ratio=...</td>\n",
       "      <td>0.261723</td>\n",
       "      <td>0.067090</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3.410863</td>\n",
       "      <td>RandomForestRegressor(random_state=2023)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>616.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.597341</td>\n",
       "      <td>RandomForestRegressor(random_state=2023)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1906.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2.437141</td>\n",
       "      <td>RandomForestRegressor(random_state=2023)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>516.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>RandomForestRegressor(random_state=2023)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3.618368</td>\n",
       "      <td>RandomForestRegressor(random_state=2023)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>831.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.702168</td>\n",
       "      <td>RandomForestRegressor(random_state=2023)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>252.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4.592474</td>\n",
       "      <td>ElasticNet(alpha=0.9435871670614078, l1_ratio=...</td>\n",
       "      <td>0.556117</td>\n",
       "      <td>0.927980</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4.990262</td>\n",
       "      <td>RandomForestRegressor(random_state=2023)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1694.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>ElasticNet(alpha=0.9435871670614078, l1_ratio=...</td>\n",
       "      <td>0.222619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>ElasticNet(alpha=0.9435871670614078, l1_ratio=...</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.923575</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature_selection__split_param  \\\n",
       "0                         1.000000   \n",
       "1                         1.000000   \n",
       "2                         1.000000   \n",
       "3                         1.000000   \n",
       "4                         3.284402   \n",
       "5                         1.000000   \n",
       "6                         2.743571   \n",
       "7                         3.807730   \n",
       "8                         3.614311   \n",
       "9                         3.707944   \n",
       "10                        2.883225   \n",
       "11                        4.149169   \n",
       "12                        2.295694   \n",
       "13                        3.186457   \n",
       "14                        2.249020   \n",
       "15                        3.839467   \n",
       "16                        5.000000   \n",
       "17                        5.000000   \n",
       "18                        4.144160   \n",
       "19                        3.897614   \n",
       "20                        2.717982   \n",
       "21                        3.402399   \n",
       "22                        4.926109   \n",
       "23                        2.239479   \n",
       "24                        5.000000   \n",
       "25                        1.254060   \n",
       "26                        1.000000   \n",
       "27                        1.005896   \n",
       "28                        1.107308   \n",
       "29                        4.406906   \n",
       "30                        3.410863   \n",
       "31                        1.597341   \n",
       "32                        2.437141   \n",
       "33                        5.000000   \n",
       "34                        3.618368   \n",
       "35                        1.702168   \n",
       "36                        4.592474   \n",
       "37                        4.990262   \n",
       "38                        1.000000   \n",
       "39                        1.000000   \n",
       "\n",
       "                                           regression  regression__alpha  \\\n",
       "0   ElasticNet(alpha=0.9435871670614078, l1_ratio=...           0.943587   \n",
       "1   ElasticNet(alpha=0.9435871670614078, l1_ratio=...           0.901154   \n",
       "2   ElasticNet(alpha=0.9435871670614078, l1_ratio=...           0.843921   \n",
       "3   ElasticNet(alpha=0.9435871670614078, l1_ratio=...           1.000000   \n",
       "4   ElasticNet(alpha=0.9435871670614078, l1_ratio=...           0.985515   \n",
       "5   ElasticNet(alpha=0.9435871670614078, l1_ratio=...           0.743924   \n",
       "6   ElasticNet(alpha=0.9435871670614078, l1_ratio=...           0.387402   \n",
       "7   ElasticNet(alpha=0.9435871670614078, l1_ratio=...           0.975746   \n",
       "8   ElasticNet(alpha=0.9435871670614078, l1_ratio=...           0.533968   \n",
       "9   ElasticNet(alpha=0.9435871670614078, l1_ratio=...           0.581160   \n",
       "10  ElasticNet(alpha=0.9435871670614078, l1_ratio=...           0.324929   \n",
       "11  ElasticNet(alpha=0.9435871670614078, l1_ratio=...           0.721623   \n",
       "12  ElasticNet(alpha=0.9435871670614078, l1_ratio=...           0.649691   \n",
       "13  ElasticNet(alpha=0.9435871670614078, l1_ratio=...           0.237075   \n",
       "14  ElasticNet(alpha=0.9435871670614078, l1_ratio=...           0.504889   \n",
       "15           RandomForestRegressor(random_state=2023)                NaN   \n",
       "16           RandomForestRegressor(random_state=2023)                NaN   \n",
       "17           RandomForestRegressor(random_state=2023)                NaN   \n",
       "18           RandomForestRegressor(random_state=2023)                NaN   \n",
       "19           RandomForestRegressor(random_state=2023)                NaN   \n",
       "20           RandomForestRegressor(random_state=2023)                NaN   \n",
       "21           RandomForestRegressor(random_state=2023)                NaN   \n",
       "22           RandomForestRegressor(random_state=2023)                NaN   \n",
       "23           RandomForestRegressor(random_state=2023)                NaN   \n",
       "24  ElasticNet(alpha=0.9435871670614078, l1_ratio=...           1.000000   \n",
       "25           RandomForestRegressor(random_state=2023)                NaN   \n",
       "26           RandomForestRegressor(random_state=2023)                NaN   \n",
       "27           RandomForestRegressor(random_state=2023)                NaN   \n",
       "28           RandomForestRegressor(random_state=2023)                NaN   \n",
       "29  ElasticNet(alpha=0.9435871670614078, l1_ratio=...           0.261723   \n",
       "30           RandomForestRegressor(random_state=2023)                NaN   \n",
       "31           RandomForestRegressor(random_state=2023)                NaN   \n",
       "32           RandomForestRegressor(random_state=2023)                NaN   \n",
       "33           RandomForestRegressor(random_state=2023)                NaN   \n",
       "34           RandomForestRegressor(random_state=2023)                NaN   \n",
       "35           RandomForestRegressor(random_state=2023)                NaN   \n",
       "36  ElasticNet(alpha=0.9435871670614078, l1_ratio=...           0.556117   \n",
       "37           RandomForestRegressor(random_state=2023)                NaN   \n",
       "38  ElasticNet(alpha=0.9435871670614078, l1_ratio=...           0.222619   \n",
       "39  ElasticNet(alpha=0.9435871670614078, l1_ratio=...           0.000100   \n",
       "\n",
       "    regression__l1_ratio  regression__max_depth  \\\n",
       "0               1.000000                    NaN   \n",
       "1               1.000000                    NaN   \n",
       "2               1.000000                    NaN   \n",
       "3               0.015915                    NaN   \n",
       "4               0.703889                    NaN   \n",
       "5               0.000000                    NaN   \n",
       "6               0.128819                    NaN   \n",
       "7               0.854681                    NaN   \n",
       "8               0.649217                    NaN   \n",
       "9               0.544714                    NaN   \n",
       "10              0.066263                    NaN   \n",
       "11              0.930024                    NaN   \n",
       "12              0.967969                    NaN   \n",
       "13              0.058609                    NaN   \n",
       "14              0.786739                    NaN   \n",
       "15                   NaN                   21.0   \n",
       "16                   NaN                   50.0   \n",
       "17                   NaN                   48.0   \n",
       "18                   NaN                   27.0   \n",
       "19                   NaN                   30.0   \n",
       "20                   NaN                   28.0   \n",
       "21                   NaN                   11.0   \n",
       "22                   NaN                    2.0   \n",
       "23                   NaN                   31.0   \n",
       "24              0.000000                    NaN   \n",
       "25                   NaN                    4.0   \n",
       "26                   NaN                    8.0   \n",
       "27                   NaN                   40.0   \n",
       "28                   NaN                   49.0   \n",
       "29              0.067090                    NaN   \n",
       "30                   NaN                   29.0   \n",
       "31                   NaN                   20.0   \n",
       "32                   NaN                   48.0   \n",
       "33                   NaN                   15.0   \n",
       "34                   NaN                   10.0   \n",
       "35                   NaN                   43.0   \n",
       "36              0.927980                    NaN   \n",
       "37                   NaN                   43.0   \n",
       "38              0.000000                    NaN   \n",
       "39              0.923575                    NaN   \n",
       "\n",
       "    regression__min_samples_split  regression__n_estimators  \n",
       "0                             NaN                       NaN  \n",
       "1                             NaN                       NaN  \n",
       "2                             NaN                       NaN  \n",
       "3                             NaN                       NaN  \n",
       "4                             NaN                       NaN  \n",
       "5                             NaN                       NaN  \n",
       "6                             NaN                       NaN  \n",
       "7                             NaN                       NaN  \n",
       "8                             NaN                       NaN  \n",
       "9                             NaN                       NaN  \n",
       "10                            NaN                       NaN  \n",
       "11                            NaN                       NaN  \n",
       "12                            NaN                       NaN  \n",
       "13                            NaN                       NaN  \n",
       "14                            NaN                       NaN  \n",
       "15                           25.0                     628.0  \n",
       "16                           25.0                    1891.0  \n",
       "17                           25.0                    1714.0  \n",
       "18                           21.0                    1055.0  \n",
       "19                           18.0                     124.0  \n",
       "20                           25.0                    2000.0  \n",
       "21                           24.0                     882.0  \n",
       "22                           23.0                    1709.0  \n",
       "23                           25.0                    1676.0  \n",
       "24                            NaN                       NaN  \n",
       "25                           24.0                    1593.0  \n",
       "26                            2.0                    2000.0  \n",
       "27                           11.0                     746.0  \n",
       "28                           18.0                    1728.0  \n",
       "29                            NaN                       NaN  \n",
       "30                           19.0                     616.0  \n",
       "31                           19.0                    1906.0  \n",
       "32                            6.0                     516.0  \n",
       "33                           15.0                     134.0  \n",
       "34                            3.0                     831.0  \n",
       "35                           22.0                     252.0  \n",
       "36                            NaN                       NaN  \n",
       "37                           10.0                    1694.0  \n",
       "38                            NaN                       NaN  \n",
       "39                            NaN                       NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_res_sorted = cv_res.sort_values(\"rank_test_score\")\n",
    "pd.DataFrame(list(cv_res_sorted[\"params\"]))\n",
    "#cv_res_sorted[[\"params\", \"mean_test_score\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save model trained on the whole training data set and optimal paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "idx_best_EN_model = cv_res[\"mean_test_score\"][:NUM_SEARCHES].argmax()\n",
    "idx_best_RF_model = cv_res[\"mean_test_score\"][NUM_SEARCHES:].argmax() + NUM_SEARCHES\n",
    "\n",
    "if SAVE_RESULTS:\n",
    "    os.makedirs(OUTDIR / \"regression\" / RADIOMICS_OPTION, exist_ok=True)\n",
    "    dst = OUTDIR / \"regression\" / RADIOMICS_OPTION / f\"Bayesian_results_{NUM_SEARCHES}_iterations_RFvsEN.xlsx\"\n",
    "    cv_res.to_excel(dst)\n",
    "    print(\"Saved hyperparams search to : \", dst)\n",
    "\n",
    "    \n",
    "    save_dst = OUTDIR / \"regression\" / RADIOMICS_OPTION\n",
    "    \n",
    "    # save optimal parameters as yaml: \n",
    "    dst = save_dst / \"SpearmanRed1_RF_opt_params.yml\"\n",
    "    data = {**cv_res.iloc[idx_best_RF_model, :].params}\n",
    "    if \"regression\" in data: \n",
    "        data.pop(\"regression\")\n",
    "    with open(dst, 'w') as outfile:\n",
    "        yaml.dump(data, outfile, default_flow_style=False)\n",
    "        print(\"saved params to \", dst)\n",
    "        \n",
    "\n",
    "    # save optimal parameters as yaml: \n",
    "    dst = save_dst / \"SpearmanRed1_EN_opt_params.yml\"\n",
    "    data = {**cv_res.iloc[idx_best_EN_model, :].params} # make copy to keep original dict unchanged\n",
    "    if \"regression\" in data: \n",
    "        data.pop(\"regression\")\n",
    "    with open(dst, 'w') as outfile:\n",
    "        yaml.dump(data, outfile, default_flow_style=False)\n",
    "        print(\"saved params to \", dst)\n",
    "        \n",
    "\n",
    "    #---- set best performing en/rf models\n",
    "    #create a pipeline\n",
    "    reg_RF = Pipeline([\n",
    "    #('scaler', StandardScaler()),  \n",
    "    ('feature_selection', SpearmanReducerCont()),\n",
    "    ('regression', RandomForestRegressor())\n",
    "    ]) \n",
    "    #Set params\n",
    "    np.random.seed(2023)\n",
    "    reg_RF.set_params(**cv_res.iloc[idx_best_RF_model, :].params)\n",
    "    reg_RF.fit(X_Tr, Y_Tr)\n",
    "    dst = save_dst / f\"SpearmanRed1_RF_opt.p\"\n",
    "    with open(dst, \"wb\") as fp:\n",
    "        pickle.dump(reg_RF, fp)\n",
    "        print(\"Saved model to \", dst)\n",
    "\n",
    "\n",
    "    #create a pipeline\n",
    "    reg_EN = Pipeline([\n",
    "    #('scaler', StandardScaler()),  \n",
    "    ('feature_selection', SpearmanReducerCont()),\n",
    "    ('regression', ElasticNet())\n",
    "    ]) \n",
    "    reg_EN.set_params(**cv_res.iloc[idx_best_EN_model, :].params)\n",
    "    reg_EN.fit(X_Tr, Y_Tr)\n",
    "    dst = save_dst / f\"SpearmanRed1_EN_opt.p\"\n",
    "    with open(dst, \"wb\") as fp:\n",
    "        pickle.dump(reg_EN, fp)\n",
    "        print(\"Saved model to \", dst)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt3-9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
