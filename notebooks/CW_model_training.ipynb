{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CW_model_training.ipynb \n",
    "\n",
    "This is based on the original notebook by the main author of the paper (`RADIPOP_model_training.ipynb`).\n",
    "Since I need to reuse it on new data, I might as well clean it up a bit. \n",
    "\n",
    "\n",
    "However, currently it is not finished... #TODO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import numba\n",
    "from typing import Literal, Union\n",
    "from glob import glob\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, r2_score, RocCurveDisplay\n",
    "# see https://stackoverflow.com/questions/60321389/sklearn-importerror-cannot-import-name-plot-roc-curve\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing  import StandardScaler\n",
    "\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from scipy.stats import ttest_ind\n",
    "from collections import defaultdict\n",
    "import seaborn as sns\n",
    "import skopt\n",
    "import time\n",
    "import re \n",
    "\n",
    "import radipop_utils \n",
    "import radipop_utils.visualization\n",
    "import radipop_utils.features\n",
    "from radipop_utils.features import SpearmanReducerCont\n",
    "import radipop_utils.utils\n",
    "from radipop_utils.utils import get_files_dict_by_regex_pattern\n",
    "\n",
    "import radipop_utils.load_data\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# load user/ system specific env variables:\n",
    "from dotenv import dotenv_values, find_dotenv\n",
    "config = dotenv_values(find_dotenv())  # load environment variables as dictionary\n",
    "\n",
    "path = Path(os.path.abspath(radipop_utils.__file__))\n",
    "RADIPOP_PACKAGE_ROOT = path.parent.parent\n",
    "\n",
    "\n",
    "##------  You will likely need to change this \n",
    "DATA_ROOT_DIRECTORY = Path(config[\"DATA_ROOT_DIRECTORY\"])\n",
    "OUTDIR = DATA_ROOT_DIRECTORY / \"radiomics\" / \"Dataset125_LSS\" \n",
    "DATASET = \"Dataset125_LSS\"\n",
    "RADIOMICS_OPTION = \"radipop_median\"\n",
    "NUM_SEARCHES = 10\n",
    "SEARCH_SCORING_METRIC = \"neg_root_mean_squared_error\",  # \"neg_root_mean_squared_error\"  \"r2\"\n",
    "##-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the the data: \n",
    "- load radiomics and HVPG values \n",
    "- utilize our custom split (previously defined and stratified on sex, scanner, status)\n",
    "- normalized the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load features and combine with predicted values: \n",
    "\n",
    "\n",
    "paths_and_hvpg_data_file = DATA_ROOT_DIRECTORY / \"tabular_data\" / \"paths_and_hvpg_values\" / f\"file_paths_and_hvpg_data_{DATASET}.xlsx\"\n",
    "radiomics_dir = DATA_ROOT_DIRECTORY / \"radiomics\" / \"Dataset125_LSS\" / RADIOMICS_OPTION\n",
    "\n",
    "# df_paths = pd.read_excel(paths_and_hvpg_data_file)\n",
    "# df_paths\n",
    "\n",
    "\n",
    "\n",
    "df = radipop_utils.load_data.get_HVPG_values_and_radiomics_paths(hvpg_data_file=paths_and_hvpg_data_file, radiomics_dir=radiomics_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the data is complete\n",
    "m = df[\"radiomics-features: liver\"].isna() | df[\"radiomics-features: spleen\"].isna()\n",
    "assert len(df[m])==0, f\"some radiomics data is missing: Check {list(df[m]['id'])}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop not completed radiomics for now ... this does no harm if the data is complete\n",
    "df_  = df.dropna(subset=[\"radiomics-features: liver\", \"radiomics-features: spleen\"])\n",
    "\n",
    "# load radiomics data for completed calcs\n",
    "df_radiomics = radipop_utils.load_data.read_and_combined_radiomics_features(df_)\n",
    "df_merged = df.merge(df_radiomics, on='id', how='inner')\n",
    "\n",
    "# final filtered dataframe \n",
    "dff = df_merged.filter(regex=\"^id|^y|^set type|^Tr split|^liver|^spleen\")\n",
    "dff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data was already done before hand. Otherwise you might want to do this now\n",
    "m_Tr = dff[\"set type\"] == \"Tr\"\n",
    "m_iTs = dff[\"set type\"] == \"internal Ts\"\n",
    "m_eTs = dff[\"set type\"] == \"external Ts\"\n",
    "\n",
    "df_Tr  = dff[m_Tr]\n",
    "df_iTs = dff[m_iTs]\n",
    "df_eTs = dff[m_eTs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(df_Tr)\n",
    "# display(df_iTs)\n",
    "# display(df_eTs)\n",
    "\n",
    "print(f\"{len(df_Tr)=}, {len(df_eTs)=}, {len(df_iTs)=}\")\n",
    "set(df[\"set type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract indices for stratified CV:\n",
    "\n",
    "df_Tr = df_Tr.reset_index(drop=True)\n",
    "split_indices_CV5_Tr = []\n",
    "for i in range(5):\n",
    "    m = df_Tr[\"Tr split\"] == i\n",
    "    idx_split_tr = df_Tr[m].index.to_numpy()\n",
    "    idx_split_ts = df_Tr[~m].index.to_numpy()\n",
    "    split_indices_CV5_Tr.append([idx_split_tr, idx_split_ts])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df_Tr[\"y\"].mean(), df_Tr[\"y\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract np arrays\n",
    "X_Tr,  Y_Tr  = df_Tr.filter(regex=\"^liver|^spleen\").values, df_Tr[\"y\"].values\n",
    "X_iTs, Y_iTs = df_iTs.filter(regex=\"^liver|^spleen\").values, df_iTs[\"y\"].values\n",
    "X_eTs, Y_eTs = df_eTs.filter(regex=\"^liver|^spleen\").values, df_eTs[\"y\"].values\n",
    "\n",
    "\n",
    "# # Normalize mostly for numerical stability. Also important for ElasticNet and just good practice in general\n",
    "\n",
    "transformer = StandardScaler().fit(X_Tr)  # fit on trainig data only\n",
    "\n",
    "X_TrN = transformer.transform(X_Tr)\n",
    "X_iTs = transformer.transform(X_iTs)\n",
    "X_eTs = transformer.transform(X_eTs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot dendrogram\n",
    "corr = spearmanr(X_Tr).correlation\n",
    "\n",
    "# Ensure the correlation matrix is symmetric\n",
    "corr = (corr + corr.T) / 2\n",
    "np.fill_diagonal(corr, 1)\n",
    "\n",
    "# plt.matshow(corr)\n",
    "# plt.show()\n",
    "\n",
    "# We convert the correlation matrix to a distance matrix before performing\n",
    "# hierarchical clustering using Ward's linkage.\n",
    "distance_matrix = 1 - np.abs(corr)\n",
    "dist_linkage = hierarchy.ward(squareform(distance_matrix))\n",
    "plt.figure()\n",
    "dendro = hierarchy.dendrogram(\n",
    "    dist_linkage, no_labels=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decide on a rought range for the cut parameters for dendrogram\n",
    "split_params = [0.5, 0.75, 1, 2.75,  5, 7.5, 10]\n",
    "for split_param in split_params:\n",
    "    selector = SpearmanReducerCont(split_param=split_param)\n",
    "    print(f\"Selected features at height {split_param}:\", len(selector.fit(X_Tr, Y_Tr).selected_features))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit on `Tr` data with CV and estimate best model + hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bounds for hyperparameters\n",
    "param_bounds_rf = {\n",
    "    'feature_selection__split_param' : skopt.space.Real(1,5, prior = \"uniform\"),\n",
    "    'regression' : [RandomForestRegressor(random_state=2023)],\n",
    "    'regression__n_estimators': skopt.space.Integer(100, 2000),\n",
    "    'regression__max_depth': skopt.space.Integer(1, 50),\n",
    "    'regression__min_samples_split': skopt.space.Integer(2, 25)#,\n",
    "}\n",
    "\n",
    "\n",
    "param_bounds_en = {\n",
    "                 'feature_selection__split_param' : skopt.space.Real(1,5, prior = \"uniform\"),\n",
    "                 'regression' : [ElasticNet(random_state=2023)],\n",
    "                 'regression__alpha': skopt.space.Real(0.0001, 1.0, 'uniform'),\n",
    "                 'regression__l1_ratio': skopt.space.Real(0, 1.0, 'uniform')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a pipeline\n",
    "reg_RF = Pipeline([\n",
    "  #('scaler', StandardScaler()),  \n",
    "  ('feature_selection', SpearmanReducerCont()),\n",
    "  ('regression', RandomForestRegressor())\n",
    "]) \n",
    "\n",
    "# cv5 = KFold(5, shuffle=True, random_state=2023)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#try out models\n",
    "opt0 = skopt.BayesSearchCV(\n",
    "    reg_RF,\n",
    "    [(param_bounds_en, NUM_SEARCHES), (param_bounds_rf, NUM_SEARCHES)],\n",
    "    cv=split_indices_CV5_Tr,\n",
    "    scoring=SEARCH_SCORING_METRIC,\n",
    "    verbose=True,\n",
    "    random_state=2023,\n",
    "    n_jobs = 6\n",
    ")\n",
    "opt0.fit(X_Tr, Y_Tr)\n",
    "\n",
    "display(opt0.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_res = pd.DataFrame(opt0.cv_results_)\n",
    "cv_res\n",
    "cv_res.iloc[:, :].reset_index().loc[:, \"mean_test_score\"].plot()\n",
    "plt.grid()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_res_sorted = cv_res.sort_values(\"rank_test_score\")\n",
    "pd.DataFrame(list(cv_res_sorted[\"params\"]))\n",
    "#cv_res_sorted[[\"params\", \"mean_test_score\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = OUTDIR / \"regression\" / RADIOMICS_OPTION / f\"Bayesian_results_{NUM_SEARCHES}_iterations_RFvsEN.xlsx\"\n",
    "cv_res.to_excel(dst)\n",
    "print(\"Saved hyperparams search to : \", dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model trained on the whole training data set and optimal paramters\n",
    "\n",
    "idx_best_EN_model = cv_res[\"mean_test_score\"][:NUM_SEARCHES].argmax()\n",
    "idx_best_RF_model = cv_res[\"mean_test_score\"][NUM_SEARCHES:].argmax() + NUM_SEARCHES\n",
    "\n",
    "os.makedirs(OUTDIR / \"regression\" / RADIOMICS_OPTION, exist_ok=True)\n",
    "save_dst = OUTDIR / \"regression\" / RADIOMICS_OPTION\n",
    "\n",
    "# save optimal parameters as yaml: \n",
    "dst = save_dst / \"SpearmanRed1_RF_opt_params.yml\"\n",
    "data = {**cv_res.iloc[idx_best_RF_model, :].params}\n",
    "if \"regression\" in data: \n",
    "    data.pop(\"regression\")\n",
    "with open(dst, 'w') as outfile:\n",
    "    yaml.dump(data, outfile, default_flow_style=False)\n",
    "    print(\"saved params to \", dst)\n",
    "    \n",
    "\n",
    "# save optimal parameters as yaml: \n",
    "dst = save_dst / \"SpearmanRed1_EN_opt_params.yml\"\n",
    "data = {**cv_res.iloc[idx_best_EN_model, :].params} # make copy to keep original dict unchanged\n",
    "if \"regression\" in data: \n",
    "    data.pop(\"regression\")\n",
    "with open(dst, 'w') as outfile:\n",
    "    yaml.dump(data, outfile, default_flow_style=False)\n",
    "    print(\"saved params to \", dst)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#---- set best performing en/rf models\n",
    "#create a pipeline\n",
    "reg_RF = Pipeline([\n",
    "  #('scaler', StandardScaler()),  \n",
    "  ('feature_selection', SpearmanReducerCont()),\n",
    "  ('regression', RandomForestRegressor())\n",
    "]) \n",
    "#Set params\n",
    "np.random.seed(2023)\n",
    "reg_RF.set_params(**cv_res.iloc[idx_best_RF_model, :].params)\n",
    "reg_RF.fit(X_Tr, Y_Tr)\n",
    "dst = save_dst / f\"SpearmanRed1_RF_opt.p\"\n",
    "with open(dst, \"wb\") as fp:\n",
    "    pickle.dump(reg_RF, fp)\n",
    "    print(\"Saved model to \", dst)\n",
    "\n",
    "\n",
    "#create a pipeline\n",
    "reg_EN = Pipeline([\n",
    "  #('scaler', StandardScaler()),  \n",
    "  ('feature_selection', SpearmanReducerCont()),\n",
    "  ('regression', ElasticNet())\n",
    "]) \n",
    "reg_EN.set_params(**cv_res.iloc[idx_best_EN_model, :].params)\n",
    "reg_EN.fit(X_Tr, Y_Tr)\n",
    "dst = save_dst / f\"SpearmanRed1_EN_opt.p\"\n",
    "with open(dst, \"wb\") as fp:\n",
    "    pickle.dump(reg_EN, fp)\n",
    "    print(\"Saved model to \", dst)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt3-9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
